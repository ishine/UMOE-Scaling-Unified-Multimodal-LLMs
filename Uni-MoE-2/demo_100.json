[
    {
        "id": 307547,
        "conversations": [
            {
                "from": "human",
                "value": "<image>\nWhere is Pulloveria based?\nA. new york\nB. toronto\nC. hamburg\nD. vienna\nAnswer with the option's letter from the given choices directly."
            },
            {
                "from": "gpt",
                "value": "D"
            }
        ],
        "images": [
            "llava_image_tune/coco/train2017/000000039928.jpg"
        ],
        "textual_length": 1000
    },
    {
        "id": 331667,
        "conversations": [
            {
                "from": "human",
                "value": "<image>\nPlease provide the bounding box coordinate of the region this sentence describes: vase by correct rounds that is almost out of shot."
            },
            {
                "from": "gpt",
                "value": "[0.17, 0.0, 0.29, 0.43]"
            },
            {
                "from": "human",
                "value": "Please provide a short description for this region: [0.2, 0.1, 0.76, 0.91]."
            },
            {
                "from": "gpt",
                "value": "Main vase big."
            },
            {
                "from": "human",
                "value": "Please provide a short description for this region: [0.17, 0.0, 0.29, 0.43]."
            },
            {
                "from": "gpt",
                "value": "Green on edge of image."
            },
            {
                "from": "human",
                "value": "Please provide a short description for this region: [0.2, 0.1, 0.76, 0.91]."
            },
            {
                "from": "gpt",
                "value": "Large vase."
            },
            {
                "from": "human",
                "value": "Please provide the bounding box coordinate of the region this sentence describes: vase on top left."
            },
            {
                "from": "gpt",
                "value": "[0.17, 0.0, 0.29, 0.43]"
            },
            {
                "from": "human",
                "value": "Please provide a short description for this region: [0.17, 0.0, 0.29, 0.43]."
            },
            {
                "from": "gpt",
                "value": "A barely visible large green vase."
            },
            {
                "from": "human",
                "value": "Please provide a short description for this region: [0.17, 0.54, 0.43, 0.96]."
            },
            {
                "from": "gpt",
                "value": "Small vase."
            },
            {
                "from": "human",
                "value": "Please provide the bounding box coordinate of the region this sentence describes: rock very top left vase."
            },
            {
                "from": "gpt",
                "value": "[0.17, 0.0, 0.29, 0.43]"
            }
        ],
        "images": [
            "llava_image_tune/coco/train2017/000000230966.jpg"
        ],
        "textual_length": 1000
    },
    {
        "id": 227199,
        "conversations": [
            {
                "from": "human",
                "value": "<image>\nHow many real dogs are there?\nAnswer the question using a single word or phrase."
            },
            {
                "from": "gpt",
                "value": "2"
            },
            {
                "from": "human",
                "value": "What color is the sheet?"
            },
            {
                "from": "gpt",
                "value": "White"
            },
            {
                "from": "human",
                "value": "How many dogs are shown?"
            },
            {
                "from": "gpt",
                "value": "2"
            },
            {
                "from": "human",
                "value": "Does the dog need his nails trimmed?"
            },
            {
                "from": "gpt",
                "value": "No"
            },
            {
                "from": "human",
                "value": "Can you name these two breeds of dogs?"
            },
            {
                "from": "gpt",
                "value": "Chihuahua and dachshund"
            },
            {
                "from": "human",
                "value": "What color is the dog's eyes?"
            },
            {
                "from": "gpt",
                "value": "Brown"
            }
        ],
        "images": [
            "llava_image_tune/coco/train2017/000000502284.jpg"
        ],
        "textual_length": 1000
    },
    {
        "id": 445995,
        "conversations": [
            {
                "from": "human",
                "value": "<image>\nPlease provide the bounding box coordinate of the region this sentence describes: the giraffe has dark eyes."
            },
            {
                "from": "gpt",
                "value": "[0.35, 0.41, 0.46, 0.49]"
            },
            {
                "from": "human",
                "value": "Please provide a short description for this region: [0.75, 0.72, 0.81, 0.8]."
            },
            {
                "from": "gpt",
                "value": "The nostril on the face."
            },
            {
                "from": "human",
                "value": "Please provide a short description for this region: [0.17, 0.06, 0.72, 0.08]."
            },
            {
                "from": "gpt",
                "value": "Yellow stripe on wall."
            },
            {
                "from": "human",
                "value": "Please provide a short description for this region: [0.3, 0.49, 0.33, 0.54]."
            },
            {
                "from": "gpt",
                "value": "Giraffe has spot on face."
            },
            {
                "from": "human",
                "value": "Please provide a short description for this region: [0.75, 0.73, 0.8, 0.8]."
            },
            {
                "from": "gpt",
                "value": "A black nostril of a giraffe."
            },
            {
                "from": "human",
                "value": "Please provide the bounding box coordinate of the region this sentence describes: A grey giraffe ear."
            },
            {
                "from": "gpt",
                "value": "[0.17, 0.23, 0.33, 0.41]"
            },
            {
                "from": "human",
                "value": "Please provide the bounding box coordinate of the region this sentence describes: the opened dark eye."
            },
            {
                "from": "gpt",
                "value": "[0.34, 0.42, 0.47, 0.5]"
            },
            {
                "from": "human",
                "value": "Please provide the bounding box coordinate of the region this sentence describes: giraffe has spot on face."
            },
            {
                "from": "gpt",
                "value": "[0.3, 0.55, 0.35, 0.6]"
            },
            {
                "from": "human",
                "value": "Please provide the bounding box coordinate of the region this sentence describes: the giraffe has large nostrils."
            },
            {
                "from": "gpt",
                "value": "[0.74, 0.71, 0.81, 0.81]"
            },
            {
                "from": "human",
                "value": "Please provide the bounding box coordinate of the region this sentence describes: the right nostril of a giraffe."
            },
            {
                "from": "gpt",
                "value": "[0.73, 0.7, 0.81, 0.83]"
            }
        ],
        "images": [
            "llava_image_tune/vg/VG_100K/2316155.jpg"
        ],
        "textual_length": 1000
    },
    {
        "id": 68807,
        "conversations": [
            {
                "from": "human",
                "value": "<image>\nWhat do you see happening in this image?"
            },
            {
                "from": "gpt",
                "value": "The scene features a white horse pulling a horse carriage down a street, with several individuals surrounding the carriage. On one side of the street, a bicyclist is riding, and another bicycle can be spotted further away. There are also many people around the carriage, including walkers, runners, and individuals on their bicycles.\n\nSome of the people are positioned behind the horse and carriage, while others can be seen at various distances and locations within the scene. This creates a lively and bustling atmosphere with different activities taking place on this street."
            }
        ],
        "images": [
            "llava_image_tune/coco/train2017/000000311982.jpg"
        ],
        "textual_length": 1000
    },
    {
        "id": 524196,
        "conversations": [
            {
                "from": "human",
                "value": "<image>\nWho is the author of this book?\nAnswer the question using a single word or phrase."
            },
            {
                "from": "gpt",
                "value": "Sharon Salzberg"
            },
            {
                "from": "human",
                "value": "What is the title of this book?"
            },
            {
                "from": "gpt",
                "value": "Real Happiness at Work: Meditations for Accomplishment, Achievement, and Peace"
            },
            {
                "from": "human",
                "value": "What type of book is this?"
            },
            {
                "from": "gpt",
                "value": "Business & Money"
            },
            {
                "from": "human",
                "value": "Is this a financial book?"
            },
            {
                "from": "gpt",
                "value": "Yes"
            },
            {
                "from": "human",
                "value": "Is this a journey related book?"
            },
            {
                "from": "gpt",
                "value": "No"
            }
        ],
        "images": [
            "llava_image_tune/ocr_vqa/images/761168990.jpg"
        ],
        "textual_length": 1000
    },
    {
        "id": 465803,
        "conversations": [
            {
                "from": "human",
                "value": "<image>\nWhat animal is white?\nAnswer the question using a single word or phrase."
            },
            {
                "from": "gpt",
                "value": "Bird"
            },
            {
                "from": "human",
                "value": "Is the beak closed or open?"
            },
            {
                "from": "gpt",
                "value": "Open"
            },
            {
                "from": "human",
                "value": "Do you see a polar bear or a duck in the image?"
            },
            {
                "from": "gpt",
                "value": "No"
            },
            {
                "from": "human",
                "value": "Do these animals have different species?"
            },
            {
                "from": "gpt",
                "value": "No"
            }
        ],
        "images": [
            "llava_image_tune/gqa/images/2339721.jpg"
        ],
        "textual_length": 1000
    },
    {
        "id": 171965,
        "conversations": [
            {
                "from": "human",
                "value": "<image>\nWhy is there four strings in the air?\nAnswer the question using a single word or phrase."
            },
            {
                "from": "gpt",
                "value": "4"
            },
            {
                "from": "human",
                "value": "What is the man holding onto?"
            },
            {
                "from": "gpt",
                "value": "Kite"
            },
            {
                "from": "human",
                "value": "Does the man appear to be in control of the kite?"
            },
            {
                "from": "gpt",
                "value": "Yes"
            },
            {
                "from": "human",
                "value": "What object is colorfully designed?"
            },
            {
                "from": "gpt",
                "value": "Kite"
            }
        ],
        "images": [
            "llava_image_tune/coco/train2017/000000090989.jpg"
        ],
        "textual_length": 1000
    },
    {
        "id": 542602,
        "conversations": [
            {
                "from": "human",
                "value": "<image>\nWho wrote this book?\nAnswer the question using a single word or phrase."
            },
            {
                "from": "gpt",
                "value": "Edgar H. Schein"
            },
            {
                "from": "human",
                "value": "What is the title of this book?"
            },
            {
                "from": "gpt",
                "value": "The Corporate Culture Survival Guide"
            },
            {
                "from": "human",
                "value": "What is the genre of this book?"
            },
            {
                "from": "gpt",
                "value": "Business & Money"
            },
            {
                "from": "human",
                "value": "Is this a financial book?"
            },
            {
                "from": "gpt",
                "value": "Yes"
            },
            {
                "from": "human",
                "value": "Is this a crafts or hobbies related book?"
            },
            {
                "from": "gpt",
                "value": "No"
            }
        ],
        "images": [
            "llava_image_tune/ocr_vqa/images/470293713.jpg"
        ],
        "textual_length": 1000
    },
    {
        "id": 546174,
        "conversations": [
            {
                "from": "human",
                "value": "<image>\nWho is the author of this book?\nAnswer the question using a single word or phrase."
            },
            {
                "from": "gpt",
                "value": "B J Kirven"
            },
            {
                "from": "human",
                "value": "What is the title of this book?"
            },
            {
                "from": "gpt",
                "value": "Wicked Whispers Spoke Their Names"
            },
            {
                "from": "human",
                "value": "What type of book is this?"
            },
            {
                "from": "gpt",
                "value": "Literature & Fiction"
            },
            {
                "from": "human",
                "value": "Is this book related to Literature & Fiction?"
            },
            {
                "from": "gpt",
                "value": "Yes"
            },
            {
                "from": "human",
                "value": "Is this book related to Gay & Lesbian?"
            },
            {
                "from": "gpt",
                "value": "No"
            }
        ],
        "images": [
            "llava_image_tune/ocr_vqa/images/1511472251.jpg"
        ],
        "textual_length": 1000
    },
    {
        "id": 425087,
        "conversations": [
            {
                "from": "human",
                "value": "<image>\nPlease provide a short description for this region: [0.13, 0.74, 0.19, 0.77]."
            },
            {
                "from": "gpt",
                "value": "The small box on the counter."
            },
            {
                "from": "human",
                "value": "Please provide the bounding box coordinate of the region this sentence describes: all the fixtures are chrome."
            },
            {
                "from": "gpt",
                "value": "[0.41, 0.58, 0.53, 0.71]"
            },
            {
                "from": "human",
                "value": "Please provide a short description for this region: [0.23, 0.62, 0.36, 0.71]."
            },
            {
                "from": "gpt",
                "value": "The rolled white colored hand towels."
            },
            {
                "from": "human",
                "value": "Please provide the bounding box coordinate of the region this sentence describes: the towels are white."
            },
            {
                "from": "gpt",
                "value": "[0.22, 0.61, 0.35, 0.72]"
            },
            {
                "from": "human",
                "value": "Please provide the bounding box coordinate of the region this sentence describes: two bars of soap lay ready."
            },
            {
                "from": "gpt",
                "value": "[0.22, 0.69, 0.31, 0.75]"
            },
            {
                "from": "human",
                "value": "Please provide a short description for this region: [0.45, 0.63, 1.0, 0.83]."
            },
            {
                "from": "gpt",
                "value": "The large white bath tub."
            },
            {
                "from": "human",
                "value": "Please provide the bounding box coordinate of the region this sentence describes: grey and white tile."
            },
            {
                "from": "gpt",
                "value": "[0.59, 0.17, 0.87, 0.36]"
            },
            {
                "from": "human",
                "value": "Please provide the bounding box coordinate of the region this sentence describes: the bathtub is white."
            },
            {
                "from": "gpt",
                "value": "[0.56, 0.7, 0.76, 0.83]"
            },
            {
                "from": "human",
                "value": "Please provide the bounding box coordinate of the region this sentence describes: the flash reflection on the wall."
            },
            {
                "from": "gpt",
                "value": "[0.83, 0.17, 1.0, 0.21]"
            },
            {
                "from": "human",
                "value": "Please provide the bounding box coordinate of the region this sentence describes: the tiles are marble."
            },
            {
                "from": "gpt",
                "value": "[0.6, 0.19, 0.99, 0.49]"
            }
        ],
        "images": [
            "llava_image_tune/vg/VG_100K/2341561.jpg"
        ],
        "textual_length": 1000
    },
    {
        "id": 103117,
        "conversations": [
            {
                "from": "human",
                "value": "<image>\nWhat activity is going on between the woman and the child in this scene?"
            },
            {
                "from": "gpt",
                "value": "In this scene, a woman and a child are sitting together at a table in a restaurant. The woman is engaged in conversation with the child while they share a meal. They are surrounded by cutlery and food items, such as a pizza, and cups on the table. It appears that they are enjoying their time together, bonding over the shared meal, and having a meaningful conversation, which forms an essential part of social interactions, particularly between family members or friends."
            }
        ],
        "images": [
            "llava_image_tune/coco/train2017/000000007946.jpg"
        ],
        "textual_length": 1000
    },
    {
        "id": 63632,
        "conversations": [
            {
                "from": "human",
                "value": "<image>\nWhat's happening in the scene?"
            },
            {
                "from": "gpt",
                "value": "The scene depicts a person riding a skateboard across the street while carrying a bag, likely containing groceries or some purchases. They appear to be wearing a helmet for safety. There are multiple cars in the image, with one positioned far ahead in the background and another one close to the left edge of the image. \n\nSeveral other people can be seen in the area, but they are relatively smaller and farther away from the main person on the skateboard. Numerous traffic lights are dispersed throughout the image indicating a busy street or intersection."
            }
        ],
        "images": [
            "llava_image_tune/coco/train2017/000000367969.jpg"
        ],
        "textual_length": 1000
    },
    {
        "id": 282771,
        "conversations": [
            {
                "from": "human",
                "value": "<image>\nWho is wearing the most safety gear?\nA. man\nB. woman\nC. bike\nD. no one\nAnswer with the option's letter from the given choices directly."
            },
            {
                "from": "gpt",
                "value": "A"
            }
        ],
        "images": [
            "llava_image_tune/coco/train2017/000000555254.jpg"
        ],
        "textual_length": 1000
    },
    {
        "id": 451630,
        "conversations": [
            {
                "from": "human",
                "value": "<image>\nWhich kind of material is used to make the cups to the left of the other cup?\nAnswer the question using a single word or phrase."
            },
            {
                "from": "gpt",
                "value": "Plastic"
            },
            {
                "from": "human",
                "value": "Is there any food near the container made of plastic?"
            },
            {
                "from": "gpt",
                "value": "Yes"
            },
            {
                "from": "human",
                "value": "Is there either a cup or a bag that is made of plastic?"
            },
            {
                "from": "gpt",
                "value": "Yes"
            },
            {
                "from": "human",
                "value": "How does the container near the food look, red or black?"
            },
            {
                "from": "gpt",
                "value": "Black"
            },
            {
                "from": "human",
                "value": "Is the green fruit to the left of the food near the container?"
            },
            {
                "from": "gpt",
                "value": "Yes"
            },
            {
                "from": "human",
                "value": "What kind of clothing is brown?"
            },
            {
                "from": "gpt",
                "value": "Pants"
            },
            {
                "from": "human",
                "value": "What is the color of the trousers?"
            },
            {
                "from": "gpt",
                "value": "Brown"
            },
            {
                "from": "human",
                "value": "Is the container to the left or to the right of the fruit?"
            },
            {
                "from": "gpt",
                "value": "Right"
            },
            {
                "from": "human",
                "value": "Is the fruit in the cup white or is it green?"
            },
            {
                "from": "gpt",
                "value": "Green"
            },
            {
                "from": "human",
                "value": "Are there both cups and utensils in this image?"
            },
            {
                "from": "gpt",
                "value": "Yes"
            },
            {
                "from": "human",
                "value": "On which side are the eggs?"
            },
            {
                "from": "gpt",
                "value": "Right"
            },
            {
                "from": "human",
                "value": "What kind of food is to the right of the utensils?"
            },
            {
                "from": "gpt",
                "value": "Eggs"
            },
            {
                "from": "human",
                "value": "Are there cups in the picture?"
            },
            {
                "from": "gpt",
                "value": "Yes"
            },
            {
                "from": "human",
                "value": "Are the eggs to the right of the cup the fruit is in?"
            },
            {
                "from": "gpt",
                "value": "Yes"
            },
            {
                "from": "human",
                "value": "Is there a fruit in this picture that is orange?"
            },
            {
                "from": "gpt",
                "value": "No"
            },
            {
                "from": "human",
                "value": "What's the fruit in?"
            },
            {
                "from": "gpt",
                "value": "Cup"
            },
            {
                "from": "human",
                "value": "What kind of food is to the right of the fruit in the cup?"
            },
            {
                "from": "gpt",
                "value": "Eggs"
            },
            {
                "from": "human",
                "value": "Which kind of food is to the right of the fruit?"
            },
            {
                "from": "gpt",
                "value": "Eggs"
            }
        ],
        "images": [
            "llava_image_tune/gqa/images/2400059.jpg"
        ],
        "textual_length": 1000
    },
    {
        "id": 101729,
        "conversations": [
            {
                "from": "human",
                "value": "<image>\nWhat nutritional benefits can one expect from this dish?"
            },
            {
                "from": "gpt",
                "value": "The dish shown in the image, containing meat and broccoli, offers a variety of nutritional benefits. Broccoli is a low-calorie vegetable that is high in vitamins C and K, as well as fiber, which promotes digestion and a healthy gut. Additionally, broccoli contains various antioxidants and minerals, such as calcium, potassium, and iron, which can contribute to overall health.\n\nThe meat in the dish provides a good source of protein, essential for maintaining and building muscle mass, as well as supporting an array of physiological processes. Meat also contains essential nutrients like iron, vitamin B12, and zinc, which can support immune function, metabolism, and brain health.\n\nThe combination of meat and vegetables in this dish provides a well-rounded meal with balanced nutrients, offering both health benefits from the vegetables and a rich source of protein from the meat."
            }
        ],
        "images": [
            "llava_image_tune/coco/train2017/000000466035.jpg"
        ],
        "textual_length": 1000
    },
    {
        "id": 277534,
        "conversations": [
            {
                "from": "human",
                "value": "<image>\nHow was the sauce for the spaghetti warmed?\nA. restaurant\nB. microwave\nC. oven\nD. stove top\nAnswer with the option's letter from the given choices directly."
            },
            {
                "from": "gpt",
                "value": "D"
            }
        ],
        "images": [
            "llava_image_tune/coco/train2017/000000396691.jpg"
        ],
        "textual_length": 1000
    },
    {
        "id": 400182,
        "conversations": [
            {
                "from": "human",
                "value": "<image>\nPlease provide a short description for this region: [0.69, 0.08, 0.72, 0.13]."
            },
            {
                "from": "gpt",
                "value": "Round blue traffic sign with white arrow."
            },
            {
                "from": "human",
                "value": "Please provide the bounding box coordinate of the region this sentence describes: a flyer taped to the pole."
            },
            {
                "from": "gpt",
                "value": "[0.58, 0.86, 0.7, 0.99]"
            },
            {
                "from": "human",
                "value": "Please provide the bounding box coordinate of the region this sentence describes: white squares on the road."
            },
            {
                "from": "gpt",
                "value": "[0.17, 0.58, 0.83, 0.72]"
            },
            {
                "from": "human",
                "value": "Please provide a short description for this region: [0.62, 0.47, 0.76, 0.6]."
            },
            {
                "from": "gpt",
                "value": "Front wheel of a vehicle."
            },
            {
                "from": "human",
                "value": "Please provide a short description for this region: [0.58, 0.24, 0.82, 0.57]."
            },
            {
                "from": "gpt",
                "value": "A white suv on the street."
            },
            {
                "from": "human",
                "value": "Please provide a short description for this region: [0.17, 0.3, 0.3, 0.37]."
            },
            {
                "from": "gpt",
                "value": "Grass on median between car lanes."
            },
            {
                "from": "human",
                "value": "Please provide a short description for this region: [0.52, 0.09, 0.7, 0.2]."
            },
            {
                "from": "gpt",
                "value": "Grey car on paved road."
            },
            {
                "from": "human",
                "value": "Please provide a short description for this region: [0.49, 0.7, 0.59, 0.81]."
            },
            {
                "from": "gpt",
                "value": "Warning and hazard stickers."
            },
            {
                "from": "human",
                "value": "Please provide the bounding box coordinate of the region this sentence describes: front headlight on a vehicle."
            },
            {
                "from": "gpt",
                "value": "[0.67, 0.4, 0.79, 0.48]"
            },
            {
                "from": "human",
                "value": "Please provide a short description for this region: [0.62, 0.12, 0.65, 0.15]."
            },
            {
                "from": "gpt",
                "value": "Rear brake light on a vehicle."
            }
        ],
        "images": [
            "llava_image_tune/vg/VG_100K/2374599.jpg"
        ],
        "textual_length": 1000
    },
    {
        "id": 355672,
        "conversations": [
            {
                "from": "human",
                "value": "<image>\nPlease provide the bounding box coordinate of the region this sentence describes: larger zebra."
            },
            {
                "from": "gpt",
                "value": "[0.22, 0.02, 0.84, 0.94]"
            },
            {
                "from": "human",
                "value": "Please provide a short description for this region: [0.41, 0.17, 0.88, 0.97]."
            },
            {
                "from": "gpt",
                "value": "Right zeb."
            },
            {
                "from": "human",
                "value": "Please provide the bounding box coordinate of the region this sentence describes: 2 zebras."
            },
            {
                "from": "gpt",
                "value": "[0.41, 0.17, 0.88, 0.97]"
            },
            {
                "from": "human",
                "value": "Please provide a short description for this region: [0.41, 0.17, 0.88, 0.97]."
            },
            {
                "from": "gpt",
                "value": "Zebra on rite."
            },
            {
                "from": "human",
                "value": "Please provide a short description for this region: [0.41, 0.17, 0.88, 0.97]."
            },
            {
                "from": "gpt",
                "value": "Smaller one."
            },
            {
                "from": "human",
                "value": "Please provide a short description for this region: [0.22, 0.02, 0.84, 0.94]."
            },
            {
                "from": "gpt",
                "value": "Giraffe closest to log."
            },
            {
                "from": "human",
                "value": "Please provide a short description for this region: [0.22, 0.02, 0.84, 0.94]."
            },
            {
                "from": "gpt",
                "value": "Zebra behind."
            }
        ],
        "images": [
            "llava_image_tune/coco/train2017/000000522653.jpg"
        ],
        "textual_length": 1000
    },
    {
        "id": 168941,
        "conversations": [
            {
                "from": "human",
                "value": "<image>\nWhere is the lawn mower?\nAnswer the question using a single word or phrase."
            },
            {
                "from": "gpt",
                "value": "Outside"
            },
            {
                "from": "human",
                "value": "Is this a blender?"
            },
            {
                "from": "gpt",
                "value": "No"
            },
            {
                "from": "human",
                "value": "Is this a living room?"
            },
            {
                "from": "gpt",
                "value": "No"
            }
        ],
        "images": [
            "llava_image_tune/coco/train2017/000000148102.jpg"
        ],
        "textual_length": 1000
    },
    {
        "id": 579054,
        "conversations": [
            {
                "from": "human",
                "value": "<image>\nWho wrote this book?\nAnswer the question using a single word or phrase."
            },
            {
                "from": "gpt",
                "value": "Dean Fearing"
            },
            {
                "from": "human",
                "value": "What is the title of this book?"
            },
            {
                "from": "gpt",
                "value": "The Texas Food Bible: From Legendary Dishes to New Classics"
            },
            {
                "from": "human",
                "value": "What is the genre of this book?"
            },
            {
                "from": "gpt",
                "value": "Cookbooks, Food & Wine"
            },
            {
                "from": "human",
                "value": "Is this book related to Cookbooks, Food & Wine?"
            },
            {
                "from": "gpt",
                "value": "Yes"
            },
            {
                "from": "human",
                "value": "Is this book related to Children's Books?"
            },
            {
                "from": "gpt",
                "value": "No"
            }
        ],
        "images": [
            "llava_image_tune/ocr_vqa/images/1455574309.jpg"
        ],
        "textual_length": 1000
    },
    {
        "id": 150898,
        "conversations": [
            {
                "from": "human",
                "value": "<image>\nWhat is one potential problem that might arise in this small bathroom setup?"
            },
            {
                "from": "gpt",
                "value": "One potential problem that might arise in the small bathroom setup is limited space for maneuvering and storage. With a white toilet occupying a significant portion of the space, there might not be enough room for comfortable usage or storage of other essential bathroom items, such as toiletries or cleaning supplies. The presence of a plunger beside the toilet also suggests possible plumbing issues, which could require more frequent maintenance and cause inconvenience in a confined space. Solutions to this problem might include optimizing the bathroom layout or considering space-saving fixtures and storage solutions to maximize the available space and make the bathroom more functional and comfortable."
            }
        ],
        "images": [
            "llava_image_tune/coco/train2017/000000012461.jpg"
        ],
        "textual_length": 1000
    },
    {
        "id": 125921,
        "conversations": [
            {
                "from": "human",
                "value": "<image>\nWhat safety precautions should be considered when interacting with giraffes?"
            },
            {
                "from": "gpt",
                "value": "When interacting with giraffes, it is essential to follow safety precautions to ensure the safety of both humans and the animals. In this image, a man is feeding two giraffes out of his hands. While this can be an incredible experience, possible safety measures to consider include:\n\n1. Supervision: Always have an experienced handler, trainer, or staff member present during the interaction. They can guide you on how to approach and feed the giraffes and ensure that both the animals and humans are safe.\n\n2. Maintain a safe distance: Although the man in the image is close to the giraffes, it is usually advised to maintain a certain distance. Giraffes have powerful and long necks that can cause harm if they become scared or aggressive. Follow the instructions given by the handler regarding the recommended distance.\n\n3. Be aware of your surroundings: Pay attention to any barriers, fencing, or other features designed to keep the giraffes and people safe. Do not cross these boundaries unless instructed by staff or handler.\n\n4. Feed the giraffes appropriately: Use the right type of food provided by the handler or staff. Avoid feeding them with your personal food or anything they are not allowed to eat, as it may cause health issues.\n\n5. Stay calm and move slowly: Avoid sudden movements and loud noises that may startle the giraffes. They are generally gentle animals but can become nervous and unpredictable if threatened or frightened.\n\n6. Follow staff or handler's instructions: Always listen to the directions given by the experienced personnel, as they have the knowledge of the animals' behavior, preferences, and potential risks.\n\nBy taking these precautions, you can minimize the risk of accidents and contribute to a positive and safe experience for both yourself and the giraffes."
            }
        ],
        "images": [
            "llava_image_tune/coco/train2017/000000107054.jpg"
        ],
        "textual_length": 1000
    },
    {
        "id": 174743,
        "conversations": [
            {
                "from": "human",
                "value": "<image>\nHow many pieces of fruit are in this image?\nAnswer the question using a single word or phrase."
            },
            {
                "from": "gpt",
                "value": "1"
            },
            {
                "from": "human",
                "value": "What color is the music player?"
            },
            {
                "from": "gpt",
                "value": "Silver"
            },
            {
                "from": "human",
                "value": "Is someone getting ready to do a craft project?"
            },
            {
                "from": "gpt",
                "value": "No"
            },
            {
                "from": "human",
                "value": "Is this person prepared for international travel?"
            },
            {
                "from": "gpt",
                "value": "Yes"
            },
            {
                "from": "human",
                "value": "Is there a flashlight in the photo?"
            },
            {
                "from": "gpt",
                "value": "No"
            }
        ],
        "images": [
            "llava_image_tune/coco/train2017/000000287958.jpg"
        ],
        "textual_length": 1000
    },
    {
        "id": 522525,
        "conversations": [
            {
                "from": "human",
                "value": "<image>\nWhich place is it?\nAnswer the question using a single word or phrase."
            },
            {
                "from": "gpt",
                "value": "Airport"
            }
        ],
        "images": [
            "llava_image_tune/gqa/images/2345477.jpg"
        ],
        "textual_length": 1000
    },
    {
        "id": 415727,
        "conversations": [
            {
                "from": "human",
                "value": "<image>\nPlease provide a short description for this region: [0.77, 0.33, 0.89, 0.59]."
            },
            {
                "from": "gpt",
                "value": "Man with glasses looking over his shoulder."
            },
            {
                "from": "human",
                "value": "Please provide a short description for this region: [0.21, 0.33, 0.27, 0.4]."
            },
            {
                "from": "gpt",
                "value": "Brown bags hanging from ceiling."
            },
            {
                "from": "human",
                "value": "Please provide the bounding box coordinate of the region this sentence describes: a peeson selling produce."
            },
            {
                "from": "gpt",
                "value": "[0.29, 0.36, 0.43, 0.54]"
            },
            {
                "from": "human",
                "value": "Please provide a short description for this region: [0.48, 0.4, 0.69, 0.61]."
            },
            {
                "from": "gpt",
                "value": "Man leaning over produce."
            },
            {
                "from": "human",
                "value": "Please provide a short description for this region: [0.29, 0.35, 0.43, 0.53]."
            },
            {
                "from": "gpt",
                "value": "Man with blue bag."
            },
            {
                "from": "human",
                "value": "Please provide the bounding box coordinate of the region this sentence describes: many heads of green brocolli."
            },
            {
                "from": "gpt",
                "value": "[0.63, 0.69, 0.72, 0.78]"
            },
            {
                "from": "human",
                "value": "Please provide a short description for this region: [0.14, 0.54, 0.22, 0.6]."
            },
            {
                "from": "gpt",
                "value": "A sign with a price on it."
            },
            {
                "from": "human",
                "value": "Please provide the bounding box coordinate of the region this sentence describes: a red and white striped canopy."
            },
            {
                "from": "gpt",
                "value": "[0.41, 0.33, 0.49, 0.42]"
            },
            {
                "from": "human",
                "value": "Please provide the bounding box coordinate of the region this sentence describes: The man has glasses."
            },
            {
                "from": "gpt",
                "value": "[0.79, 0.34, 0.84, 0.4]"
            },
            {
                "from": "human",
                "value": "Please provide the bounding box coordinate of the region this sentence describes: Brick chimney on the roof."
            },
            {
                "from": "gpt",
                "value": "[0.71, 0.11, 0.75, 0.16]"
            }
        ],
        "images": [
            "llava_image_tune/vg/VG_100K/2353914.jpg"
        ],
        "textual_length": 1000
    },
    {
        "id": 221826,
        "conversations": [
            {
                "from": "human",
                "value": "<image>\nWhy are these trains stopped here?\nAnswer the question using a single word or phrase."
            },
            {
                "from": "gpt",
                "value": "Train station"
            },
            {
                "from": "human",
                "value": "How many train tracks are here?"
            },
            {
                "from": "gpt",
                "value": "2"
            },
            {
                "from": "human",
                "value": "What color are the trains?"
            },
            {
                "from": "gpt",
                "value": "Yellow"
            },
            {
                "from": "human",
                "value": "What color is the first car?"
            },
            {
                "from": "gpt",
                "value": "Yellow"
            },
            {
                "from": "human",
                "value": "Is it sunny?"
            },
            {
                "from": "gpt",
                "value": "Yes"
            },
            {
                "from": "human",
                "value": "Are the two trains from the same company?"
            },
            {
                "from": "gpt",
                "value": "Yes"
            },
            {
                "from": "human",
                "value": "How many people in the picture?"
            },
            {
                "from": "gpt",
                "value": "0"
            },
            {
                "from": "human",
                "value": "Is this place a train station?"
            },
            {
                "from": "gpt",
                "value": "Yes"
            },
            {
                "from": "human",
                "value": "Is this an industrial site?"
            },
            {
                "from": "gpt",
                "value": "No"
            }
        ],
        "images": [
            "llava_image_tune/coco/train2017/000000431764.jpg"
        ],
        "textual_length": 1000
    },
    {
        "id": 608432,
        "conversations": [
            {
                "from": "human",
                "value": "<image>\nProvide a one-sentence caption for the provided image.\nReference OCR token: ndon, Lakeland, Ter, Insurance, Ho"
            },
            {
                "from": "gpt",
                "value": "Two men playing baseball with the word Lakeland behind one of them."
            }
        ],
        "images": [
            "llava_image_tune/textvqa/train_images/c33d2707794d4f7b.jpg"
        ],
        "textual_length": 1000
    },
    {
        "id": 201843,
        "conversations": [
            {
                "from": "human",
                "value": "<image>\nAre all three men wearing hats?\nAnswer the question using a single word or phrase."
            },
            {
                "from": "gpt",
                "value": "No"
            },
            {
                "from": "human",
                "value": "Is everyone playing?"
            },
            {
                "from": "gpt",
                "value": "No"
            },
            {
                "from": "human",
                "value": "What sport is being played?"
            },
            {
                "from": "gpt",
                "value": "Tennis"
            },
            {
                "from": "human",
                "value": "Is this a professional game?"
            },
            {
                "from": "gpt",
                "value": "Yes"
            }
        ],
        "images": [
            "llava_image_tune/coco/train2017/000000460673.jpg"
        ],
        "textual_length": 1000
    },
    {
        "id": 204026,
        "conversations": [
            {
                "from": "human",
                "value": "<image>\nIs the sky blue?\nAnswer the question using a single word or phrase."
            },
            {
                "from": "gpt",
                "value": "Yes"
            },
            {
                "from": "human",
                "value": "How many street signs are there?"
            },
            {
                "from": "gpt",
                "value": "2"
            },
            {
                "from": "human",
                "value": "Are these \"streets\" or :Ave\"?"
            },
            {
                "from": "gpt",
                "value": "Streets"
            }
        ],
        "images": [
            "llava_image_tune/coco/train2017/000000464261.jpg"
        ],
        "textual_length": 1000
    },
    {
        "id": 522512,
        "conversations": [
            {
                "from": "human",
                "value": "<image>\nIs it an outdoors scene?\nAnswer the question using a single word or phrase."
            },
            {
                "from": "gpt",
                "value": "Yes"
            }
        ],
        "images": [
            "llava_image_tune/gqa/images/1159824.jpg"
        ],
        "textual_length": 1000
    },
    {
        "id": 313146,
        "conversations": [
            {
                "from": "human",
                "value": "<image>\nWhat is the person holding in their left hand?\nA. sword\nB. chopstick\nC. fork\nD. racquet\nAnswer with the option's letter from the given choices directly."
            },
            {
                "from": "gpt",
                "value": "C"
            }
        ],
        "images": [
            "llava_image_tune/coco/train2017/000000362966.jpg"
        ],
        "textual_length": 1000
    },
    {
        "id": 99611,
        "conversations": [
            {
                "from": "human",
                "value": "<image>\nWhat factors would a farmer need to consider to ensure the wellbeing of these two farm animals?"
            },
            {
                "from": "gpt",
                "value": "To ensure the wellbeing of the sheep and the donkey (or mule) in the grassy pasture, a farmer must consider several factors including nutrition, shelter, companionship, and healthcare. \n\n1. Nutrition: Both animals should have access to a sufficient amount of quality food, such as fresh grass or hay, and clean water to maintain their health. A farmer should also regularly monitor their nutritional needs and adjust their diet as needed.\n\n2. Shelter: Although the image shows animals outside in a grassy area, it is crucial that they have access to proper shelter, protecting them from harsh weather conditions or predators. A dry, clean, and well-ventilated shelter will help maintain the animals' health and wellbeing.\n\n3. Companionship: Since many farm animals, including sheep and donkeys, are social creatures, it is essential to ensure they have companionship. Keeping social animals together can help reduce stress and improve their overall wellbeing.\n\n4. Healthcare: Regular healthcare check-ups and vaccinations, as well as prompt treatment of any illnesses or injuries, ensure that the animals stay healthy. Farmers should also have a good understanding of the specific health requirements and potential issues related to each species.\n\nBy addressing these factors, a farmer can contribute to the wellbeing, happiness, and longevity of both the sheep and the donkey in the pasture."
            }
        ],
        "images": [
            "llava_image_tune/coco/train2017/000000204375.jpg"
        ],
        "textual_length": 1000
    },
    {
        "id": 171931,
        "conversations": [
            {
                "from": "human",
                "value": "<image>\nHow many chairs are there?\nAnswer the question using a single word or phrase."
            },
            {
                "from": "gpt",
                "value": "3"
            },
            {
                "from": "human",
                "value": "Is the Blackboard clean?"
            },
            {
                "from": "gpt",
                "value": "No"
            },
            {
                "from": "human",
                "value": "Is this a classroom?"
            },
            {
                "from": "gpt",
                "value": "Yes"
            },
            {
                "from": "human",
                "value": "Is there a room fan?"
            },
            {
                "from": "gpt",
                "value": "No"
            }
        ],
        "images": [
            "llava_image_tune/coco/train2017/000000152664.jpg"
        ],
        "textual_length": 1000
    },
    {
        "id": 384106,
        "conversations": [
            {
                "from": "human",
                "value": "<image>\nPlease provide the bounding box coordinate of the region this sentence describes: woman walking down the street."
            },
            {
                "from": "gpt",
                "value": "[0.64, 0.8, 0.71, 0.87]"
            },
            {
                "from": "human",
                "value": "Please provide the bounding box coordinate of the region this sentence describes: part of  a door."
            },
            {
                "from": "gpt",
                "value": "[0.7, 0.43, 0.73, 0.53]"
            },
            {
                "from": "human",
                "value": "Please provide a short description for this region: [0.2, 0.84, 0.51, 0.87]."
            },
            {
                "from": "gpt",
                "value": "People sitting at tables."
            },
            {
                "from": "human",
                "value": "Please provide a short description for this region: [0.75, 0.68, 0.92, 0.8]."
            },
            {
                "from": "gpt",
                "value": "Potted plants hanging off the wall."
            },
            {
                "from": "human",
                "value": "Please provide a short description for this region: [0.01, 0.74, 0.1, 0.87]."
            },
            {
                "from": "gpt",
                "value": "Maroon door."
            },
            {
                "from": "human",
                "value": "Please provide a short description for this region: [0.41, 0.29, 0.64, 0.35]."
            },
            {
                "from": "gpt",
                "value": "The building is cream in color."
            },
            {
                "from": "human",
                "value": "Please provide the bounding box coordinate of the region this sentence describes: clock on building face."
            },
            {
                "from": "gpt",
                "value": "[0.41, 0.45, 0.49, 0.52]"
            },
            {
                "from": "human",
                "value": "Please provide the bounding box coordinate of the region this sentence describes: part of a plant."
            },
            {
                "from": "gpt",
                "value": "[0.82, 0.72, 0.87, 0.8]"
            },
            {
                "from": "human",
                "value": "Please provide a short description for this region: [0.64, 0.81, 0.69, 0.85]."
            },
            {
                "from": "gpt",
                "value": "Woman wearing sunglasses."
            },
            {
                "from": "human",
                "value": "Please provide the bounding box coordinate of the region this sentence describes: these are some people."
            },
            {
                "from": "gpt",
                "value": "[0.07, 0.82, 0.74, 0.87]"
            }
        ],
        "images": [
            "llava_image_tune/vg/VG_100K_2/2396393.jpg"
        ],
        "textual_length": 1000
    },
    {
        "id": 448981,
        "conversations": [
            {
                "from": "human",
                "value": "<image>\nPlease provide a short description for this region: [0.67, 0.18, 0.71, 0.24]."
            },
            {
                "from": "gpt",
                "value": "Picture on the wall."
            },
            {
                "from": "human",
                "value": "Please provide the bounding box coordinate of the region this sentence describes: framed items on a wall."
            },
            {
                "from": "gpt",
                "value": "[0.67, 0.17, 0.71, 0.33]"
            },
            {
                "from": "human",
                "value": "Please provide the bounding box coordinate of the region this sentence describes: blanket on the bed."
            },
            {
                "from": "gpt",
                "value": "[0.19, 0.51, 0.51, 0.79]"
            },
            {
                "from": "human",
                "value": "Please provide the bounding box coordinate of the region this sentence describes: A picture on the wall."
            },
            {
                "from": "gpt",
                "value": "[0.96, 0.27, 0.98, 0.31]"
            },
            {
                "from": "human",
                "value": "Please provide a short description for this region: [0.94, 0.22, 1.0, 0.32]."
            },
            {
                "from": "gpt",
                "value": "Pictures on an orange wall."
            },
            {
                "from": "human",
                "value": "Please provide a short description for this region: [0.32, 0.36, 0.38, 0.41]."
            },
            {
                "from": "gpt",
                "value": "The hand of a person."
            },
            {
                "from": "human",
                "value": "Please provide the bounding box coordinate of the region this sentence describes: the floor is made of wood."
            },
            {
                "from": "gpt",
                "value": "[0.01, 0.7, 0.3, 0.84]"
            },
            {
                "from": "human",
                "value": "Please provide the bounding box coordinate of the region this sentence describes: cut out pictures on wall."
            },
            {
                "from": "gpt",
                "value": "[0.92, 0.22, 0.99, 0.3]"
            },
            {
                "from": "human",
                "value": "Please provide a short description for this region: [0.29, 0.47, 0.76, 0.59]."
            },
            {
                "from": "gpt",
                "value": "Woman with messy hair laying on bed."
            }
        ],
        "images": [
            "llava_image_tune/vg/VG_100K_2/2416248.jpg"
        ],
        "textual_length": 1000
    },
    {
        "id": 451278,
        "conversations": [
            {
                "from": "human",
                "value": "<image>\nDoes the pillow that is to the right of the other pillows look white or green?\nAnswer the question using a single word or phrase."
            },
            {
                "from": "gpt",
                "value": "White"
            },
            {
                "from": "human",
                "value": "Is there a nightstand to the left of the white bed?"
            },
            {
                "from": "gpt",
                "value": "Yes"
            },
            {
                "from": "human",
                "value": "Which kind of furniture is made of wood?"
            },
            {
                "from": "gpt",
                "value": "Nightstand"
            },
            {
                "from": "human",
                "value": "What type of furniture is made of wood?"
            },
            {
                "from": "gpt",
                "value": "Nightstand"
            },
            {
                "from": "human",
                "value": "Which type of furniture is wooden, the nightstand or the bed?"
            },
            {
                "from": "gpt",
                "value": "Nightstand"
            },
            {
                "from": "human",
                "value": "Do you see pillows to the left of the nightstand made of wood?"
            },
            {
                "from": "gpt",
                "value": "No"
            },
            {
                "from": "human",
                "value": "Which pattern is the sheet to the right of the nightstand?"
            },
            {
                "from": "gpt",
                "value": "Striped"
            },
            {
                "from": "human",
                "value": "Is there a lamp to the left of the pillows that are on top of the bed?"
            },
            {
                "from": "gpt",
                "value": "No"
            },
            {
                "from": "human",
                "value": "Is the nightstand to the left or to the right of the sheet?"
            },
            {
                "from": "gpt",
                "value": "Left"
            },
            {
                "from": "human",
                "value": "Is the bed to the right of the plastic bag?"
            },
            {
                "from": "gpt",
                "value": "Yes"
            },
            {
                "from": "human",
                "value": "What is the remote lying on?"
            },
            {
                "from": "gpt",
                "value": "Bed"
            },
            {
                "from": "human",
                "value": "Which kind of device is lying on the bed?"
            },
            {
                "from": "gpt",
                "value": "Remote control"
            },
            {
                "from": "human",
                "value": "What kind of furniture is not large?"
            },
            {
                "from": "gpt",
                "value": "Nightstand"
            },
            {
                "from": "human",
                "value": "Is there a bed or an ottoman in this scene?"
            },
            {
                "from": "gpt",
                "value": "Yes"
            },
            {
                "from": "human",
                "value": "Does the bed near the nightstand look white?"
            },
            {
                "from": "gpt",
                "value": "Yes"
            },
            {
                "from": "human",
                "value": "Is the nightstand to the left or to the right of the pillows in the center?"
            },
            {
                "from": "gpt",
                "value": "Left"
            },
            {
                "from": "human",
                "value": "What is the bag made of plastic sitting on?"
            },
            {
                "from": "gpt",
                "value": "Nightstand"
            },
            {
                "from": "human",
                "value": "What is the item of furniture that the plastic bag is sitting on?"
            },
            {
                "from": "gpt",
                "value": "Nightstand"
            },
            {
                "from": "human",
                "value": "Is there a nightstand next to the bed to the right of the purse?"
            },
            {
                "from": "gpt",
                "value": "Yes"
            },
            {
                "from": "human",
                "value": "Is the remote control lying on a bed?"
            },
            {
                "from": "gpt",
                "value": "Yes"
            },
            {
                "from": "human",
                "value": "What kind of furniture is the remote lying on?"
            },
            {
                "from": "gpt",
                "value": "Bed"
            },
            {
                "from": "human",
                "value": "Is the nightstand next to the bed both wooden and white?"
            },
            {
                "from": "gpt",
                "value": "Yes"
            },
            {
                "from": "human",
                "value": "Is this a bed or a mirror?"
            },
            {
                "from": "gpt",
                "value": "Bed"
            },
            {
                "from": "human",
                "value": "What kind of furniture is wooden?"
            },
            {
                "from": "gpt",
                "value": "Nightstand"
            },
            {
                "from": "human",
                "value": "Which side of the image is the nightstand on?"
            },
            {
                "from": "gpt",
                "value": "Left"
            },
            {
                "from": "human",
                "value": "Which side of the photo is the remote control on?"
            },
            {
                "from": "gpt",
                "value": "Right"
            },
            {
                "from": "human",
                "value": "What is sitting on the bed?"
            },
            {
                "from": "gpt",
                "value": "Remote control"
            },
            {
                "from": "human",
                "value": "What is the remote control sitting on?"
            },
            {
                "from": "gpt",
                "value": "Bed"
            },
            {
                "from": "human",
                "value": "Is the bed near the nightstand both white and small?"
            },
            {
                "from": "gpt",
                "value": "No"
            },
            {
                "from": "human",
                "value": "The bag that is sitting on the nightstand has what color?"
            },
            {
                "from": "gpt",
                "value": "Light blue"
            },
            {
                "from": "human",
                "value": "On which side is the plastic bag?"
            },
            {
                "from": "gpt",
                "value": "Left"
            },
            {
                "from": "human",
                "value": "Does the striped sheet look colorful?"
            },
            {
                "from": "gpt",
                "value": "Yes"
            },
            {
                "from": "human",
                "value": "What's the remote control lying on?"
            },
            {
                "from": "gpt",
                "value": "Bed"
            },
            {
                "from": "human",
                "value": "What device is on top of the bed?"
            },
            {
                "from": "gpt",
                "value": "Remote control"
            },
            {
                "from": "human",
                "value": "Is the remote control on top of a coffee table?"
            },
            {
                "from": "gpt",
                "value": "No"
            },
            {
                "from": "human",
                "value": "Is the nightstand to the left of a sheet?"
            },
            {
                "from": "gpt",
                "value": "Yes"
            },
            {
                "from": "human",
                "value": "What piece of furniture is to the left of the sheet?"
            },
            {
                "from": "gpt",
                "value": "Nightstand"
            },
            {
                "from": "human",
                "value": "On which side of the photo is the black purse?"
            },
            {
                "from": "gpt",
                "value": "Left"
            }
        ],
        "images": [
            "llava_image_tune/gqa/images/2394057.jpg"
        ],
        "textual_length": 1000
    },
    {
        "id": 598763,
        "conversations": [
            {
                "from": "human",
                "value": "<image>\nWho is the author of this book?\nAnswer the question using a single word or phrase."
            },
            {
                "from": "gpt",
                "value": "J.J. Haynes"
            },
            {
                "from": "human",
                "value": "What is the title of this book?"
            },
            {
                "from": "gpt",
                "value": "Ford Super Duty F-250 & F-350 Pick-ups 1999 Thru 2010: Includes Gasoline and Diesel Engines (Haynes Repair Manual)"
            },
            {
                "from": "human",
                "value": "What type of book is this?"
            },
            {
                "from": "gpt",
                "value": "Engineering & Transportation"
            },
            {
                "from": "human",
                "value": "Is this book related to Engineering & Transportation?"
            },
            {
                "from": "gpt",
                "value": "Yes"
            },
            {
                "from": "human",
                "value": "Is this book related to Parenting & Relationships?"
            },
            {
                "from": "gpt",
                "value": "No"
            }
        ],
        "images": [
            "llava_image_tune/ocr_vqa/images/1563928566.jpg"
        ],
        "textual_length": 1000
    },
    {
        "id": 197197,
        "conversations": [
            {
                "from": "human",
                "value": "<image>\nHow is the steak cooked?\nAnswer the question using a single word or phrase."
            },
            {
                "from": "gpt",
                "value": "Medium rare"
            },
            {
                "from": "human",
                "value": "What color is the plate?"
            },
            {
                "from": "gpt",
                "value": "Green"
            },
            {
                "from": "human",
                "value": "What color is the place mat?"
            },
            {
                "from": "gpt",
                "value": "Blue"
            }
        ],
        "images": [
            "llava_image_tune/coco/train2017/000000059882.jpg"
        ],
        "textual_length": 1000
    },
    {
        "id": 486194,
        "conversations": [
            {
                "from": "human",
                "value": "<image>\nWhich kind of furniture is the woman sitting on?\nAnswer the question using a single word or phrase."
            },
            {
                "from": "gpt",
                "value": "Chair"
            },
            {
                "from": "human",
                "value": "Do you see both bags and chairs there?"
            },
            {
                "from": "gpt",
                "value": "Yes"
            },
            {
                "from": "human",
                "value": "What color is the table the bag is on?"
            },
            {
                "from": "gpt",
                "value": "White"
            },
            {
                "from": "human",
                "value": "Are there both a chair and a table in the image?"
            },
            {
                "from": "gpt",
                "value": "Yes"
            },
            {
                "from": "human",
                "value": "Is there a bag to the right of the woman?"
            },
            {
                "from": "gpt",
                "value": "Yes"
            },
            {
                "from": "human",
                "value": "Are there any bags on the white table?"
            },
            {
                "from": "gpt",
                "value": "Yes"
            },
            {
                "from": "human",
                "value": "Is the woman to the left of the black bag?"
            },
            {
                "from": "gpt",
                "value": "Yes"
            },
            {
                "from": "human",
                "value": "Is there a bottle to the right of the woman?"
            },
            {
                "from": "gpt",
                "value": "No"
            },
            {
                "from": "human",
                "value": "Is she sitting on the chair on the left?"
            },
            {
                "from": "gpt",
                "value": "Yes"
            },
            {
                "from": "human",
                "value": "What is she wearing?"
            },
            {
                "from": "gpt",
                "value": "Dress"
            },
            {
                "from": "human",
                "value": "What is the woman wearing?"
            },
            {
                "from": "gpt",
                "value": "Dress"
            },
            {
                "from": "human",
                "value": "What color is the bag to the right of the other bag?"
            },
            {
                "from": "gpt",
                "value": "Red"
            }
        ],
        "images": [
            "llava_image_tune/gqa/images/2358456.jpg"
        ],
        "textual_length": 1000
    },
    {
        "id": 339709,
        "conversations": [
            {
                "from": "human",
                "value": "<image>\nPlease provide a short description for this region: [0.59, 0.25, 0.76, 0.8]."
            },
            {
                "from": "gpt",
                "value": "Violin guy."
            },
            {
                "from": "human",
                "value": "Please provide the bounding box coordinate of the region this sentence describes: man with sax."
            },
            {
                "from": "gpt",
                "value": "[0.72, 0.27, 0.91, 0.75]"
            },
            {
                "from": "human",
                "value": "Please provide a short description for this region: [0.39, 0.37, 0.61, 0.79]."
            },
            {
                "from": "gpt",
                "value": "Center man."
            },
            {
                "from": "human",
                "value": "Please provide the bounding box coordinate of the region this sentence describes: tamborine man."
            },
            {
                "from": "gpt",
                "value": "[0.23, 0.4, 0.44, 0.82]"
            },
            {
                "from": "human",
                "value": "Please provide the bounding box coordinate of the region this sentence describes: man sitting to the right of drum."
            },
            {
                "from": "gpt",
                "value": "[0.23, 0.4, 0.44, 0.82]"
            },
            {
                "from": "human",
                "value": "Please provide the bounding box coordinate of the region this sentence describes: sax player."
            },
            {
                "from": "gpt",
                "value": "[0.72, 0.27, 0.91, 0.75]"
            },
            {
                "from": "human",
                "value": "Please provide a short description for this region: [0.39, 0.37, 0.61, 0.79]."
            },
            {
                "from": "gpt",
                "value": "Guy sitting next to violin player."
            },
            {
                "from": "human",
                "value": "Please provide a short description for this region: [0.75, 0.38, 0.97, 0.82]."
            },
            {
                "from": "gpt",
                "value": "Guy far right sitting."
            },
            {
                "from": "human",
                "value": "Please provide the bounding box coordinate of the region this sentence describes: man with small round instrument in hand."
            },
            {
                "from": "gpt",
                "value": "[0.23, 0.4, 0.44, 0.82]"
            }
        ],
        "images": [
            "llava_image_tune/coco/train2017/000000455654.jpg"
        ],
        "textual_length": 1000
    },
    {
        "id": 585574,
        "conversations": [
            {
                "from": "human",
                "value": "<image>\nWho wrote this book?\nAnswer the question using a single word or phrase."
            },
            {
                "from": "gpt",
                "value": "Kelly M. Feeley"
            },
            {
                "from": "human",
                "value": "What is the title of this book?"
            },
            {
                "from": "gpt",
                "value": "Mastering Alternative Dispute Resolution (Carolina Academic Press Mastering)"
            },
            {
                "from": "human",
                "value": "What type of book is this?"
            },
            {
                "from": "gpt",
                "value": "Law"
            },
            {
                "from": "human",
                "value": "Is this book related to Law?"
            },
            {
                "from": "gpt",
                "value": "Yes"
            },
            {
                "from": "human",
                "value": "Is this book related to Computers & Technology?"
            },
            {
                "from": "gpt",
                "value": "No"
            }
        ],
        "images": [
            "llava_image_tune/ocr_vqa/images/1611632013.jpg"
        ],
        "textual_length": 1000
    },
    {
        "id": 565142,
        "conversations": [
            {
                "from": "human",
                "value": "<image>\nWho is the author of this book?\nAnswer the question using a single word or phrase."
            },
            {
                "from": "gpt",
                "value": "David J Willis"
            },
            {
                "from": "human",
                "value": "What is the title of this book?"
            },
            {
                "from": "gpt",
                "value": "Real Estate Law & Asset Protection for Texas Real Estate Investors - Third Edition"
            },
            {
                "from": "human",
                "value": "What type of book is this?"
            },
            {
                "from": "gpt",
                "value": "Business & Money"
            },
            {
                "from": "human",
                "value": "Is this book related to Business & Money?"
            },
            {
                "from": "gpt",
                "value": "Yes"
            },
            {
                "from": "human",
                "value": "Is this book related to Christian Books & Bibles?"
            },
            {
                "from": "gpt",
                "value": "No"
            }
        ],
        "images": [
            "llava_image_tune/ocr_vqa/images/1622873777.jpg"
        ],
        "textual_length": 1000
    },
    {
        "id": 186049,
        "conversations": [
            {
                "from": "human",
                "value": "<image>\nWhat vitamin is the vegetable particular high in?\nAnswer the question using a single word or phrase."
            },
            {
                "from": "gpt",
                "value": "Fiber"
            },
            {
                "from": "human",
                "value": "What is the silver object?"
            },
            {
                "from": "gpt",
                "value": "Fork"
            },
            {
                "from": "human",
                "value": "Do these items have nutrients beneficial to teeth?"
            },
            {
                "from": "gpt",
                "value": "Yes"
            },
            {
                "from": "human",
                "value": "What is the green vegetable?"
            },
            {
                "from": "gpt",
                "value": "Broccoli"
            }
        ],
        "images": [
            "llava_image_tune/coco/train2017/000000173882.jpg"
        ],
        "textual_length": 1000
    },
    {
        "id": 91509,
        "conversations": [
            {
                "from": "human",
                "value": "<image>\nHow can one infer that the man enjoys visiting pizzerias?"
            },
            {
                "from": "gpt",
                "value": "One can infer that the man enjoys visiting pizzerias based on the image, where he is sitting at a dining table in what appears to be a pizza restaurant. A pizza is placed before him on the table, alongside a cup for beverages, indicating that he has ordered a meal at this establishment. The man, wearing glasses and a white shirt, seems to be preparing to enjoy the pizza, which suggests that he is a fan of this type of food and likely frequents pizzerias to satisfy his cravings."
            }
        ],
        "images": [
            "llava_image_tune/coco/train2017/000000153616.jpg"
        ],
        "textual_length": 1000
    },
    {
        "id": 416546,
        "conversations": [
            {
                "from": "human",
                "value": "<image>\nPlease provide the bounding box coordinate of the region this sentence describes: the train is caligraphed."
            },
            {
                "from": "gpt",
                "value": "[0.49, 0.44, 0.68, 0.6]"
            },
            {
                "from": "human",
                "value": "Please provide the bounding box coordinate of the region this sentence describes: Blue and white diamonds on the wall."
            },
            {
                "from": "gpt",
                "value": "[0.85, 0.65, 0.92, 0.76]"
            },
            {
                "from": "human",
                "value": "Please provide the bounding box coordinate of the region this sentence describes: the window is open."
            },
            {
                "from": "gpt",
                "value": "[0.45, 0.33, 0.48, 0.37]"
            },
            {
                "from": "human",
                "value": "Please provide a short description for this region: [0.46, 0.2, 0.52, 0.24]."
            },
            {
                "from": "gpt",
                "value": "Big red machinery hanging under the train."
            },
            {
                "from": "human",
                "value": "Please provide the bounding box coordinate of the region this sentence describes: Blue and white diamonds on the wall."
            },
            {
                "from": "gpt",
                "value": "[0.72, 0.23, 0.95, 0.3]"
            },
            {
                "from": "human",
                "value": "Please provide a short description for this region: [0.5, 0.38, 0.54, 0.44]."
            },
            {
                "from": "gpt",
                "value": "Blue and white diamonds on the wall."
            },
            {
                "from": "human",
                "value": "Please provide a short description for this region: [0.5, 0.37, 0.57, 0.45]."
            },
            {
                "from": "gpt",
                "value": "Big red machinery hanging under the train."
            },
            {
                "from": "human",
                "value": "Please provide a short description for this region: [0.52, 0.69, 0.6, 0.78]."
            },
            {
                "from": "gpt",
                "value": "Part of  a ground."
            },
            {
                "from": "human",
                "value": "Please provide a short description for this region: [0.64, 0.33, 0.71, 0.46]."
            },
            {
                "from": "gpt",
                "value": "This is the door."
            },
            {
                "from": "human",
                "value": "Please provide a short description for this region: [0.34, 0.59, 0.99, 0.83]."
            },
            {
                "from": "gpt",
                "value": "Gravel in between tracks."
            }
        ],
        "images": [
            "llava_image_tune/vg/VG_100K/2352832.jpg"
        ],
        "textual_length": 1000
    },
    {
        "id": 295224,
        "conversations": [
            {
                "from": "human",
                "value": "<image>\nWhat does the silo behind the train store?\nA. corn\nB. grain\nC. water\nD. coal\nAnswer with the option's letter from the given choices directly."
            },
            {
                "from": "gpt",
                "value": "C"
            }
        ],
        "images": [
            "llava_image_tune/coco/train2017/000000270193.jpg"
        ],
        "textual_length": 1000
    },
    {
        "id": 310964,
        "conversations": [
            {
                "from": "human",
                "value": "<image>\nWhat is on the left side of the room?\nA. apple cart\nB. barrel\nC. wheelbarrow\nD. bench\nAnswer with the option's letter from the given choices directly."
            },
            {
                "from": "gpt",
                "value": "D"
            }
        ],
        "images": [
            "llava_image_tune/coco/train2017/000000207180.jpg"
        ],
        "textual_length": 1000
    },
    {
        "id": 623245,
        "conversations": [
            {
                "from": "human",
                "value": "<image>\nProvide a one-sentence caption for the provided image.\nReference OCR token: 11, 12, 10, 10, LaauBa, 9, 8, 7, 6"
            },
            {
                "from": "gpt",
                "value": "Silver and black face of a clock which says the number 24 on the top."
            }
        ],
        "images": [
            "llava_image_tune/textvqa/train_images/066f6d1fa2f45d09.jpg"
        ],
        "textual_length": 1000
    },
    {
        "id": 454573,
        "conversations": [
            {
                "from": "human",
                "value": "<image>\nHow is the dark animal called?\nAnswer the question using a single word or phrase."
            },
            {
                "from": "gpt",
                "value": "Dog"
            },
            {
                "from": "human",
                "value": "Do the towel and the shoe have a different colors?"
            },
            {
                "from": "gpt",
                "value": "No"
            },
            {
                "from": "human",
                "value": "Are there dark dogs in this image?"
            },
            {
                "from": "gpt",
                "value": "Yes"
            },
            {
                "from": "human",
                "value": "What is the dark animal doing, lying or walking?"
            },
            {
                "from": "gpt",
                "value": "Lying"
            },
            {
                "from": "human",
                "value": "Does the window look shut or open?"
            },
            {
                "from": "gpt",
                "value": "Shut"
            }
        ],
        "images": [
            "llava_image_tune/gqa/images/2352998.jpg"
        ],
        "textual_length": 1000
    },
    {
        "id": 599702,
        "conversations": [
            {
                "from": "human",
                "value": "<image>\nWho is the author of this book?\nAnswer the question using a single word or phrase."
            },
            {
                "from": "gpt",
                "value": "Jeremy R. Spindlove"
            },
            {
                "from": "human",
                "value": "What is the title of this book?"
            },
            {
                "from": "gpt",
                "value": "Terrorism Today: The Past, The Players, The Future (5th Edition)"
            },
            {
                "from": "human",
                "value": "What type of book is this?"
            },
            {
                "from": "gpt",
                "value": "Law"
            },
            {
                "from": "human",
                "value": "Is this book related to Law?"
            },
            {
                "from": "gpt",
                "value": "Yes"
            },
            {
                "from": "human",
                "value": "Is this book related to Comics & Graphic Novels?"
            },
            {
                "from": "gpt",
                "value": "No"
            }
        ],
        "images": [
            "llava_image_tune/ocr_vqa/images/132683113.jpg"
        ],
        "textual_length": 1000
    },
    {
        "id": 153751,
        "conversations": [
            {
                "from": "human",
                "value": "<image>\nWhat concern might surfers have at this location?"
            },
            {
                "from": "gpt",
                "value": "At this rocky shore location, surfers might face concerns regarding safe access to the water for surfing. In the image, a person is carrying a surfboard by the ocean, but the shoreline appears to be rocky, which poses an increased risk of injury while entering or exiting the water. Additionally, the presence of rocks can create unstable and potentially dangerous conditions for surfers when riding waves. Surfers must carefully navigate through the rocky shoreline and be cautious of the underwater hazards to ensure their safety while enjoying their water sport activities."
            }
        ],
        "images": [
            "llava_image_tune/coco/train2017/000000559511.jpg"
        ],
        "textual_length": 1000
    },
    {
        "id": 508434,
        "conversations": [
            {
                "from": "human",
                "value": "<image>\nDo you see giraffes there?\nAnswer the question using a single word or phrase."
            },
            {
                "from": "gpt",
                "value": "Yes"
            },
            {
                "from": "human",
                "value": "Are there any balls or fences in the image?"
            },
            {
                "from": "gpt",
                "value": "Yes"
            },
            {
                "from": "human",
                "value": "What animal is sitting on the ground?"
            },
            {
                "from": "gpt",
                "value": "Giraffe"
            },
            {
                "from": "human",
                "value": "Which place is it?"
            },
            {
                "from": "gpt",
                "value": "Field"
            },
            {
                "from": "human",
                "value": "Does the fence have white color?"
            },
            {
                "from": "gpt",
                "value": "No"
            },
            {
                "from": "human",
                "value": "Are there either any giraffes or cows?"
            },
            {
                "from": "gpt",
                "value": "Yes"
            },
            {
                "from": "human",
                "value": "Are the two animals the same species?"
            },
            {
                "from": "gpt",
                "value": "Yes"
            }
        ],
        "images": [
            "llava_image_tune/gqa/images/2348110.jpg"
        ],
        "textual_length": 1000
    },
    {
        "id": 55217,
        "conversations": [
            {
                "from": "human",
                "value": "<image>\nWhat is the man doing in the image?"
            },
            {
                "from": "gpt",
                "value": "The man in the image is preparing a pizza, putting the finishing touches on it while standing at a counter with a wooden pan underneath the pizza."
            },
            {
                "from": "human",
                "value": "Is the man wearing any protective clothing while preparing the pizza?"
            },
            {
                "from": "gpt",
                "value": "Yes, the man is wearing an apron while cooking the pizza, which helps protect his clothes from any spills or stains during the process."
            },
            {
                "from": "human",
                "value": "What is the age of the man in the image?"
            },
            {
                "from": "gpt",
                "value": "The man in the image is described as an older man. However, it's essential to note that age is relative and may vary depending on one's perspective."
            },
            {
                "from": "human",
                "value": "What will the man do after finishing preparing the pizza?"
            },
            {
                "from": "gpt",
                "value": "After finishing the preparation of the pizza and putting the final touches on it, the man will most likely place the pizza into an oven to cook."
            },
            {
                "from": "human",
                "value": "Why is using a wooden pan important when making pizza?"
            },
            {
                "from": "gpt",
                "value": "A wooden pan, often known as a pizza peel, plays a significant role in the pizza-making process, offering several benefits:\n\n1. Easy Handling: A wooden pizza peel provides a smooth surface for preparing the pizza, making it easier to slide the pizza on and off the peel when transferring it to and from the oven.\n\n2. Temperature Insulation: Wood is a poor conductor of heat, which means that using a wooden peel helps prevent burning your hands when transferring the pizza to the oven.\n\n3. Moisture Absorption: Wood is porous and can absorb any excess moisture from the dough. This helps prevent the pizza from sticking to the peel and creates a better texture for the crust.\n\n4. Flavor Enhancement: Some wooden pizza peels, especially those made of hardwoods like cherry, walnut, or maple, are thought to impart a unique, subtle flavor to the pizza crust.\n\nIn summary, using a wooden pan or pizza peel is essential in making pizza because it makes handling easier, insulates against heat, absorbs excess moisture, and can enhance the pizza's flavor."
            }
        ],
        "images": [
            "llava_image_tune/coco/train2017/000000489279.jpg"
        ],
        "textual_length": 1000
    },
    {
        "id": 278970,
        "conversations": [
            {
                "from": "human",
                "value": "<image>\nHow is this man feeling?\nA. amused\nB. shy\nC. angry\nD. excited\nAnswer with the option's letter from the given choices directly."
            },
            {
                "from": "gpt",
                "value": "C"
            }
        ],
        "images": [
            "llava_image_tune/coco/train2017/000000565041.jpg"
        ],
        "textual_length": 1000
    },
    {
        "id": 431853,
        "conversations": [
            {
                "from": "human",
                "value": "<image>\nPlease provide a short description for this region: [0.33, 0.49, 0.54, 0.71]."
            },
            {
                "from": "gpt",
                "value": "The woman's hands holding the device."
            },
            {
                "from": "human",
                "value": "Please provide a short description for this region: [0.39, 0.54, 0.44, 0.63]."
            },
            {
                "from": "gpt",
                "value": "A woman wearing a ring."
            },
            {
                "from": "human",
                "value": "Please provide a short description for this region: [0.5, 0.39, 0.7, 0.63]."
            },
            {
                "from": "gpt",
                "value": "A woman wearing a scarf."
            },
            {
                "from": "human",
                "value": "Please provide a short description for this region: [0.52, 0.46, 0.7, 0.62]."
            },
            {
                "from": "gpt",
                "value": "The scarf on the woman's neck."
            },
            {
                "from": "human",
                "value": "Please provide a short description for this region: [0.39, 0.55, 0.45, 0.61]."
            },
            {
                "from": "gpt",
                "value": "This is a ring."
            },
            {
                "from": "human",
                "value": "Please provide the bounding box coordinate of the region this sentence describes: a hand holding a cellphone."
            },
            {
                "from": "gpt",
                "value": "[0.34, 0.47, 0.5, 0.65]"
            },
            {
                "from": "human",
                "value": "Please provide the bounding box coordinate of the region this sentence describes: the woman's left hand."
            },
            {
                "from": "gpt",
                "value": "[0.37, 0.49, 0.55, 0.66]"
            },
            {
                "from": "human",
                "value": "Please provide the bounding box coordinate of the region this sentence describes: this is a hand."
            },
            {
                "from": "gpt",
                "value": "[0.26, 0.47, 0.46, 0.83]"
            },
            {
                "from": "human",
                "value": "Please provide a short description for this region: [0.52, 0.69, 0.61, 0.75]."
            },
            {
                "from": "gpt",
                "value": "Watch on woman's wrist."
            }
        ],
        "images": [
            "llava_image_tune/vg/VG_100K/2333374.jpg"
        ],
        "textual_length": 1000
    },
    {
        "id": 423855,
        "conversations": [
            {
                "from": "human",
                "value": "<image>\nPlease provide a short description for this region: [0.0, 0.68, 0.07, 0.82]."
            },
            {
                "from": "gpt",
                "value": "The bridle of a horse."
            },
            {
                "from": "human",
                "value": "Please provide a short description for this region: [0.75, 0.22, 1.0, 0.79]."
            },
            {
                "from": "gpt",
                "value": "The woman is wearing sunglasses."
            },
            {
                "from": "human",
                "value": "Please provide a short description for this region: [0.0, 0.25, 0.69, 0.45]."
            },
            {
                "from": "gpt",
                "value": "Dark green trees atop a hill."
            },
            {
                "from": "human",
                "value": "Please provide the bounding box coordinate of the region this sentence describes: a long sloping hill."
            },
            {
                "from": "gpt",
                "value": "[0.0, 0.26, 0.7, 0.43]"
            },
            {
                "from": "human",
                "value": "Please provide the bounding box coordinate of the region this sentence describes: the woman is on a saddle."
            },
            {
                "from": "gpt",
                "value": "[0.14, 0.53, 0.38, 0.7]"
            },
            {
                "from": "human",
                "value": "Please provide a short description for this region: [0.0, 0.51, 0.08, 0.81]."
            },
            {
                "from": "gpt",
                "value": "The head of a horse."
            },
            {
                "from": "human",
                "value": "Please provide the bounding box coordinate of the region this sentence describes: the ear of a horse."
            },
            {
                "from": "gpt",
                "value": "[0.73, 0.45, 0.77, 0.5]"
            },
            {
                "from": "human",
                "value": "Please provide a short description for this region: [0.0, 0.43, 0.11, 0.49]."
            },
            {
                "from": "gpt",
                "value": "A house with a black roof."
            },
            {
                "from": "human",
                "value": "Please provide the bounding box coordinate of the region this sentence describes: the woman is wearing a t-shirt."
            },
            {
                "from": "gpt",
                "value": "[0.09, 0.34, 0.5, 0.66]"
            },
            {
                "from": "human",
                "value": "Please provide a short description for this region: [0.62, 0.41, 0.66, 0.47]."
            },
            {
                "from": "gpt",
                "value": "A distant street light."
            }
        ],
        "images": [
            "llava_image_tune/vg/VG_100K/2343224.jpg"
        ],
        "textual_length": 1000
    },
    {
        "id": 604307,
        "conversations": [
            {
                "from": "human",
                "value": "<image>\nProvide a one-sentence caption for the provided image.\nReference OCR token: LERN-SP, LERI-SPIEL-SPAS, Ne7, 680, Die, Welt, in, der, SPASS, wir, leben, LERN-SPIEL-SPASS, LERN-, Die, Welt, in, der, wir, leben, Geschichten, UNISET, 00%, PictureMaking, Making, HE, KING, Acreativeu, peelmagic, canbe, andov, ligures, IOALDY, LION, iqures"
            },
            {
                "from": "gpt",
                "value": "A collection of children's books, including The Lion King and My Cats."
            }
        ],
        "images": [
            "llava_image_tune/textvqa/train_images/5ab2fdb9f3fc3b2a.jpg"
        ],
        "textual_length": 1000
    },
    {
        "id": 336652,
        "conversations": [
            {
                "from": "human",
                "value": "<image>\nPlease provide a short description for this region: [0.0, 0.18, 0.12, 0.64]."
            },
            {
                "from": "gpt",
                "value": "Frisbee middle section part of the legs extreme left."
            },
            {
                "from": "human",
                "value": "Please provide the bounding box coordinate of the region this sentence describes: center little girl white shirt behind gate."
            },
            {
                "from": "gpt",
                "value": "[0.48, 0.27, 0.61, 0.65]"
            },
            {
                "from": "human",
                "value": "Please provide a short description for this region: [0.56, 0.18, 0.75, 0.65]."
            },
            {
                "from": "gpt",
                "value": "Man in green polo."
            },
            {
                "from": "human",
                "value": "Please provide a short description for this region: [0.24, 0.18, 0.47, 0.37]."
            },
            {
                "from": "gpt",
                "value": "Man white shirt no head."
            },
            {
                "from": "human",
                "value": "Please provide the bounding box coordinate of the region this sentence describes: woman next to man black pants."
            },
            {
                "from": "gpt",
                "value": "[0.38, 0.18, 0.52, 0.61]"
            },
            {
                "from": "human",
                "value": "Please provide a short description for this region: [0.48, 0.27, 0.61, 0.65]."
            },
            {
                "from": "gpt",
                "value": "Kid by fence in white shirt."
            },
            {
                "from": "human",
                "value": "Please provide a short description for this region: [0.24, 0.18, 0.47, 0.37]."
            },
            {
                "from": "gpt",
                "value": "Guys white shirt left side."
            }
        ],
        "images": [
            "llava_image_tune/coco/train2017/000000457686.jpg"
        ],
        "textual_length": 1000
    },
    {
        "id": 17042,
        "conversations": [
            {
                "from": "human",
                "value": "<image>\nIs there a man sitting in a horse-drawn carriage in the image?"
            },
            {
                "from": "gpt",
                "value": "Yes, there is a man sitting in a horse-drawn carriage in the image."
            },
            {
                "from": "human",
                "value": "Are there people sitting at tables outside of a building in the image?"
            },
            {
                "from": "gpt",
                "value": "Yes, there are people sitting at tables outside of a building in the image. They seem to be enjoying their time at an outdoor establishment."
            },
            {
                "from": "human",
                "value": "What color is the horse pulling the carriage?"
            },
            {
                "from": "gpt",
                "value": "The horse pulling the carriage is brown and black."
            },
            {
                "from": "human",
                "value": "What color is the carriage being drawn by the horse?"
            },
            {
                "from": "gpt",
                "value": "The carriage being drawn by the horse is red and black."
            },
            {
                "from": "human",
                "value": "What type of buildings are in the surrounding area?"
            },
            {
                "from": "gpt",
                "value": "The surrounding buildings are older-looking, with a historical and charming architectural style. This setting suggests that the location could be in a historic district or a city with rich cultural heritage."
            }
        ],
        "images": [
            "llava_image_tune/coco/train2017/000000371608.jpg"
        ],
        "textual_length": 1000
    },
    {
        "id": 135906,
        "conversations": [
            {
                "from": "human",
                "value": "<image>\nWhat are the potential dietary benefits of the meal depicted?"
            },
            {
                "from": "gpt",
                "value": "The meal depicted in the image, consisting of a vegetable sandwich on a wheat roll accompanied by a side of fries, offers several dietary benefits. The open face vegetable sandwich is made of cooked vegetables, which are rich in vitamins, minerals, and dietary fiber, all of which are essential for maintaining good health. Using a wheat roll instead of white bread provides additional fiber and complex carbohydrates, promoting better digestion and sustained energy release. However, one should be mindful of the cheese fries as they can be high in calories, fat, and sodium. To further enhance the nutritional value of the meal, one could opt for a side salad or a portion of grilled vegetables instead of the fries."
            }
        ],
        "images": [
            "llava_image_tune/coco/train2017/000000098361.jpg"
        ],
        "textual_length": 1000
    },
    {
        "id": 53360,
        "conversations": [
            {
                "from": "human",
                "value": "<image>\nCan you describe the main objects in the image?"
            },
            {
                "from": "gpt",
                "value": "The main objects in the image are a bike, which is parked or standing near a bucket filled with lots of oranges. The scene appears to be set on a patio."
            },
            {
                "from": "human",
                "value": "What type of fruit is in the bucket?"
            },
            {
                "from": "gpt",
                "value": "The bucket is filled with oranges."
            },
            {
                "from": "human",
                "value": "How would you describe the appearance of the bicycle?"
            },
            {
                "from": "gpt",
                "value": "The bicycle appears to be small and cute-looking, enhancing the overall charming and pleasant atmosphere of the scene."
            },
            {
                "from": "human",
                "value": "Where is the bicycle parked or located in relation to the bucket of oranges?"
            },
            {
                "from": "gpt",
                "value": "The bicycle is parked or standing next to the bucket of oranges, with both of them placed close together on the patio."
            },
            {
                "from": "human",
                "value": "What could be the possible scenario or purpose of the bike and oranges being placed close together?"
            },
            {
                "from": "gpt",
                "value": "There are several possible scenarios or reasons for the bike and oranges being placed close together:\n\n1. Personal use: The owner of the bike and oranges may use the bike for transportation while also enjoying fresh oranges. They might have parked the bike next to the bucket after purchasing the oranges, or they simply stored the oranges on their patio for easy access.\n\n2. Selling oranges: It is possible that the owner is a vendor who sells oranges and uses the bike to transport the fruit to and from their selling location. The bike and the bucket could be set up as a small, informal display for selling oranges to passersby.\n\n3. Aesthetic purposes: The bike and the bucket of oranges may be intentionally arranged as a decorative element in a residential or commercial setting. The combination of the vibrant oranges and the charming bicycle creates a visually appealing scene that adds character and interest to the area.\n\nRegardless of the scenario, the image of the bike next to the bucket of oranges evokes a sense of liveliness and adds a touch of color and charm to the surroundings."
            }
        ],
        "images": [
            "llava_image_tune/coco/train2017/000000547662.jpg"
        ],
        "textual_length": 1000
    },
    {
        "id": 324960,
        "conversations": [
            {
                "from": "human",
                "value": "<image>\nPlease provide a short description for this region: [0.64, 0.51, 0.92, 0.78]."
            },
            {
                "from": "gpt",
                "value": "Second donut down right side."
            },
            {
                "from": "human",
                "value": "Please provide the bounding box coordinate of the region this sentence describes: pink second from top."
            },
            {
                "from": "gpt",
                "value": "[0.23, 0.39, 0.6, 0.68]"
            },
            {
                "from": "human",
                "value": "Please provide the bounding box coordinate of the region this sentence describes: middle white donut."
            },
            {
                "from": "gpt",
                "value": "[0.23, 0.39, 0.6, 0.68]"
            },
            {
                "from": "human",
                "value": "Please provide a short description for this region: [0.63, 0.31, 0.95, 0.58]."
            },
            {
                "from": "gpt",
                "value": "Bagel top right."
            },
            {
                "from": "human",
                "value": "Please provide the bounding box coordinate of the region this sentence describes: donut hidden under heart."
            },
            {
                "from": "gpt",
                "value": "[0.64, 0.51, 0.92, 0.78]"
            },
            {
                "from": "human",
                "value": "Please provide the bounding box coordinate of the region this sentence describes: largest chocolate doughnut."
            },
            {
                "from": "gpt",
                "value": "[0.09, 0.6, 0.47, 0.83]"
            },
            {
                "from": "human",
                "value": "Please provide the bounding box coordinate of the region this sentence describes: upper right donut."
            },
            {
                "from": "gpt",
                "value": "[0.63, 0.31, 0.95, 0.58]"
            },
            {
                "from": "human",
                "value": "Please provide the bounding box coordinate of the region this sentence describes: choc donut front."
            },
            {
                "from": "gpt",
                "value": "[0.09, 0.6, 0.47, 0.83]"
            },
            {
                "from": "human",
                "value": "Please provide the bounding box coordinate of the region this sentence describes: black donut at bottom."
            },
            {
                "from": "gpt",
                "value": "[0.09, 0.6, 0.47, 0.83]"
            },
            {
                "from": "human",
                "value": "Please provide a short description for this region: [0.63, 0.31, 0.95, 0.58]."
            },
            {
                "from": "gpt",
                "value": "Donut directly below heart and arrow."
            }
        ],
        "images": [
            "llava_image_tune/coco/train2017/000000346391.jpg"
        ],
        "textual_length": 1000
    },
    {
        "id": 460936,
        "conversations": [
            {
                "from": "human",
                "value": "<image>\nIs there a mug to the right of the yogurt?\nAnswer the question using a single word or phrase."
            },
            {
                "from": "gpt",
                "value": "No"
            },
            {
                "from": "human",
                "value": "Who is wearing the shirt?"
            },
            {
                "from": "gpt",
                "value": "Child"
            },
            {
                "from": "human",
                "value": "What do the wire and the blender have in common?"
            },
            {
                "from": "gpt",
                "value": "Color"
            },
            {
                "from": "human",
                "value": "Is the shirt blue or red?"
            },
            {
                "from": "gpt",
                "value": "Blue"
            },
            {
                "from": "human",
                "value": "What is the color of the child's hair?"
            },
            {
                "from": "gpt",
                "value": "Blond"
            },
            {
                "from": "human",
                "value": "Does the appliance that looks empty look white?"
            },
            {
                "from": "gpt",
                "value": "Yes"
            },
            {
                "from": "human",
                "value": "What is the food to the left of the watermelons that are in the bowl?"
            },
            {
                "from": "gpt",
                "value": "Granola"
            },
            {
                "from": "human",
                "value": "What kind of food is in the bowl that is to the right of the container?"
            },
            {
                "from": "gpt",
                "value": "Granola"
            },
            {
                "from": "human",
                "value": "What is the granola in?"
            },
            {
                "from": "gpt",
                "value": "Bowl"
            },
            {
                "from": "human",
                "value": "Does the counter have white color?"
            },
            {
                "from": "gpt",
                "value": "No"
            },
            {
                "from": "human",
                "value": "Is the blue cup to the right or to the left of the bowl made of plastic?"
            },
            {
                "from": "gpt",
                "value": "Right"
            },
            {
                "from": "human",
                "value": "Is there an apple in the bowl the granola is to the left of?"
            },
            {
                "from": "gpt",
                "value": "No"
            },
            {
                "from": "human",
                "value": "What are the watermelons in?"
            },
            {
                "from": "gpt",
                "value": "Bowl"
            },
            {
                "from": "human",
                "value": "What is in the bowl that is on the right of the photo?"
            },
            {
                "from": "gpt",
                "value": "Watermelons"
            },
            {
                "from": "human",
                "value": "Does the child sit at the counter?"
            },
            {
                "from": "gpt",
                "value": "Yes"
            },
            {
                "from": "human",
                "value": "Do you think the bowl of the watermelons is white or blue?"
            },
            {
                "from": "gpt",
                "value": "White"
            },
            {
                "from": "human",
                "value": "Who is wearing a shirt?"
            },
            {
                "from": "gpt",
                "value": "Child"
            },
            {
                "from": "human",
                "value": "What color is the bowl to the left of the other bowl?"
            },
            {
                "from": "gpt",
                "value": "White"
            },
            {
                "from": "human",
                "value": "How the white appliance is called?"
            },
            {
                "from": "gpt",
                "value": "Blender"
            },
            {
                "from": "human",
                "value": "What fruits are to the right of the granola that is to the right of the blender?"
            },
            {
                "from": "gpt",
                "value": "Watermelons"
            },
            {
                "from": "human",
                "value": "What is the food to the left of the bowl that is of the watermelons?"
            },
            {
                "from": "gpt",
                "value": "Granola"
            },
            {
                "from": "human",
                "value": "Are the watermelons to the right of the granola that is to the right of the container?"
            },
            {
                "from": "gpt",
                "value": "Yes"
            },
            {
                "from": "human",
                "value": "What is common to the shirt and the counter?"
            },
            {
                "from": "gpt",
                "value": "Color"
            },
            {
                "from": "human",
                "value": "Which kind of food is to the right of the blender?"
            },
            {
                "from": "gpt",
                "value": "Granola"
            },
            {
                "from": "human",
                "value": "Which kind of appliance is white?"
            },
            {
                "from": "gpt",
                "value": "Blender"
            },
            {
                "from": "human",
                "value": "What is on the counter?"
            },
            {
                "from": "gpt",
                "value": "Blender"
            },
            {
                "from": "human",
                "value": "Is the white object on the counter empty or full?"
            },
            {
                "from": "gpt",
                "value": "Empty"
            },
            {
                "from": "human",
                "value": "Is the blender full and white?"
            },
            {
                "from": "gpt",
                "value": "No"
            },
            {
                "from": "human",
                "value": "Are there both spoons and cups in the photograph?"
            },
            {
                "from": "gpt",
                "value": "Yes"
            },
            {
                "from": "human",
                "value": "Is the young child to the right or to the left of the cup that is of the yogurt?"
            },
            {
                "from": "gpt",
                "value": "Right"
            },
            {
                "from": "human",
                "value": "Is the blender to the left of the child?"
            },
            {
                "from": "gpt",
                "value": "Yes"
            },
            {
                "from": "human",
                "value": "Where does the young person sit?"
            },
            {
                "from": "gpt",
                "value": "Counter"
            },
            {
                "from": "human",
                "value": "On which side is the container, the left or the right?"
            },
            {
                "from": "gpt",
                "value": "Left"
            },
            {
                "from": "human",
                "value": "Which kind of appliance is to the left of the granola?"
            },
            {
                "from": "gpt",
                "value": "Blender"
            },
            {
                "from": "human",
                "value": "On which side are the watermelons?"
            },
            {
                "from": "gpt",
                "value": "Right"
            },
            {
                "from": "human",
                "value": "What kind of fruit is in the bowl on the right side?"
            },
            {
                "from": "gpt",
                "value": "Watermelons"
            },
            {
                "from": "human",
                "value": "What is the appliance that has the same color as the cord called?"
            },
            {
                "from": "gpt",
                "value": "Blender"
            },
            {
                "from": "human",
                "value": "Is the plastic bowl to the right or to the left of the cup that is of the yogurt?"
            },
            {
                "from": "gpt",
                "value": "Right"
            },
            {
                "from": "human",
                "value": "Where is the child?"
            },
            {
                "from": "gpt",
                "value": "Counter"
            },
            {
                "from": "human",
                "value": "Where is the kid?"
            },
            {
                "from": "gpt",
                "value": "Counter"
            },
            {
                "from": "human",
                "value": "What was used to make the bowl to the left of the kid, plastic or glass?"
            },
            {
                "from": "gpt",
                "value": "Plastic"
            },
            {
                "from": "human",
                "value": "Is the granola to the right of a coffee maker?"
            },
            {
                "from": "gpt",
                "value": "No"
            },
            {
                "from": "human",
                "value": "What size is the container on the left side of the photo?"
            },
            {
                "from": "gpt",
                "value": "Large"
            },
            {
                "from": "human",
                "value": "What type of appliance is shown?"
            },
            {
                "from": "gpt",
                "value": "Blender"
            },
            {
                "from": "human",
                "value": "What kind of appliance is it?"
            },
            {
                "from": "gpt",
                "value": "Blender"
            },
            {
                "from": "human",
                "value": "Which color is the cup that the blender is to the left of?"
            },
            {
                "from": "gpt",
                "value": "Blue"
            },
            {
                "from": "human",
                "value": "What is on the blue counter?"
            },
            {
                "from": "gpt",
                "value": "Blender"
            },
            {
                "from": "human",
                "value": "Where does the child sit?"
            },
            {
                "from": "gpt",
                "value": "Counter"
            },
            {
                "from": "human",
                "value": "What is in the bowl to the left of the watermelons?"
            },
            {
                "from": "gpt",
                "value": "Granola"
            }
        ],
        "images": [
            "llava_image_tune/gqa/images/2377723.jpg"
        ],
        "textual_length": 1000
    },
    {
        "id": 256548,
        "conversations": [
            {
                "from": "human",
                "value": "<image>\nWhat is an alternate spelling for the name on the license plate?\nA. harold\nB. howard\nC. harrison\nD. henry\nAnswer with the option's letter from the given choices directly."
            },
            {
                "from": "gpt",
                "value": "D"
            }
        ],
        "images": [
            "llava_image_tune/coco/train2017/000000528929.jpg"
        ],
        "textual_length": 1000
    },
    {
        "id": 570201,
        "conversations": [
            {
                "from": "human",
                "value": "<image>\nWho wrote this book?\nAnswer the question using a single word or phrase."
            },
            {
                "from": "gpt",
                "value": "Edward Shepherd Creasy"
            },
            {
                "from": "human",
                "value": "What is the title of this book?"
            },
            {
                "from": "gpt",
                "value": "The Fifteen Decisive Battles of the World: From Marathon to Waterloo (Dover Military History, Weapons, Armor)"
            },
            {
                "from": "human",
                "value": "What is the genre of this book?"
            },
            {
                "from": "gpt",
                "value": "History"
            },
            {
                "from": "human",
                "value": "Is this book related to History?"
            },
            {
                "from": "gpt",
                "value": "Yes"
            },
            {
                "from": "human",
                "value": "Is this book related to History?"
            },
            {
                "from": "gpt",
                "value": "No"
            }
        ],
        "images": [
            "llava_image_tune/ocr_vqa/images/048646170X.jpg"
        ],
        "textual_length": 1000
    },
    {
        "id": 499607,
        "conversations": [
            {
                "from": "human",
                "value": "<image>\nWhere in the photograph is the white computer, in the bottom or in the top?\nAnswer the question using a single word or phrase."
            },
            {
                "from": "gpt",
                "value": "Bottom"
            },
            {
                "from": "human",
                "value": "Are there any surfboards or dish soaps?"
            },
            {
                "from": "gpt",
                "value": "No"
            },
            {
                "from": "human",
                "value": "Are there either any black cell phones or computers?"
            },
            {
                "from": "gpt",
                "value": "No"
            },
            {
                "from": "human",
                "value": "Which color is the water that looks choppy?"
            },
            {
                "from": "gpt",
                "value": "Dark blue"
            }
        ],
        "images": [
            "llava_image_tune/gqa/images/2367120.jpg"
        ],
        "textual_length": 1000
    },
    {
        "id": 202738,
        "conversations": [
            {
                "from": "human",
                "value": "<image>\nHow many people are in this picture?\nAnswer the question using a single word or phrase."
            },
            {
                "from": "gpt",
                "value": "2"
            },
            {
                "from": "human",
                "value": "What sport are they playing?"
            },
            {
                "from": "gpt",
                "value": "Skateboarding"
            },
            {
                "from": "human",
                "value": "Is he approaching the ground at an angle?"
            },
            {
                "from": "gpt",
                "value": "Yes"
            },
            {
                "from": "human",
                "value": "Is this sport being done outdoors?"
            },
            {
                "from": "gpt",
                "value": "No"
            },
            {
                "from": "human",
                "value": "Is he wearing a protective gear?"
            },
            {
                "from": "gpt",
                "value": "Yes"
            },
            {
                "from": "human",
                "value": "What are they playing?"
            },
            {
                "from": "gpt",
                "value": "Skateboarding"
            },
            {
                "from": "human",
                "value": "What is the boy doing in the air?"
            },
            {
                "from": "gpt",
                "value": "Skateboarding"
            }
        ],
        "images": [
            "llava_image_tune/coco/train2017/000000200001.jpg"
        ],
        "textual_length": 1000
    },
    {
        "id": 62507,
        "conversations": [
            {
                "from": "human",
                "value": "<image>\nWrite a detailed description of the given image."
            },
            {
                "from": "gpt",
                "value": "The image showcases a group of young people playing a lively game of soccer on a field. There are several players actively participating, with some in action in the foreground and others scattered around the field. The sports ball is clearly visible, located towards the left side of the image.\n\nOn the sidelines, there are two benches, one on each side of the field, providing a place to rest for any substitutes. A backpack can be seen placed beside the field, suggesting that it may belong to one of the players. Overall, the atmosphere is energetic and competitive as the young players engage in the match."
            }
        ],
        "images": [
            "llava_image_tune/coco/train2017/000000237561.jpg"
        ],
        "textual_length": 1000
    },
    {
        "id": 433765,
        "conversations": [
            {
                "from": "human",
                "value": "<image>\nPlease provide a short description for this region: [0.67, 0.22, 0.72, 0.26]."
            },
            {
                "from": "gpt",
                "value": "A small black bowl."
            },
            {
                "from": "human",
                "value": "Please provide a short description for this region: [0.08, 0.09, 0.36, 0.25]."
            },
            {
                "from": "gpt",
                "value": "A white painted wall."
            },
            {
                "from": "human",
                "value": "Please provide a short description for this region: [0.86, 0.7, 0.94, 0.91]."
            },
            {
                "from": "gpt",
                "value": "Part of a brown hardwood floor."
            },
            {
                "from": "human",
                "value": "Please provide the bounding box coordinate of the region this sentence describes: One side border of the picture frame."
            },
            {
                "from": "gpt",
                "value": "[0.94, 0.01, 1.0, 0.98]"
            },
            {
                "from": "human",
                "value": "Please provide a short description for this region: [0.0, 0.92, 1.0, 0.99]."
            },
            {
                "from": "gpt",
                "value": "Bottom side border of the picture frame."
            },
            {
                "from": "human",
                "value": "Please provide the bounding box coordinate of the region this sentence describes: a large black and white cat."
            },
            {
                "from": "gpt",
                "value": "[0.23, 0.36, 0.57, 0.57]"
            },
            {
                "from": "human",
                "value": "Please provide a short description for this region: [0.59, 0.17, 0.62, 0.25]."
            },
            {
                "from": "gpt",
                "value": "A tall white candle."
            },
            {
                "from": "human",
                "value": "Please provide the bounding box coordinate of the region this sentence describes: a decorative pillow."
            },
            {
                "from": "gpt",
                "value": "[0.1, 0.53, 0.74, 0.74]"
            },
            {
                "from": "human",
                "value": "Please provide the bounding box coordinate of the region this sentence describes: cat has a white spot on chest."
            },
            {
                "from": "gpt",
                "value": "[0.44, 0.51, 0.54, 0.56]"
            },
            {
                "from": "human",
                "value": "Please provide the bounding box coordinate of the region this sentence describes: A black cat on a sofa chair."
            },
            {
                "from": "gpt",
                "value": "[0.24, 0.38, 0.56, 0.57]"
            }
        ],
        "images": [
            "llava_image_tune/vg/VG_100K/2331126.jpg"
        ],
        "textual_length": 1000
    },
    {
        "id": 221016,
        "conversations": [
            {
                "from": "human",
                "value": "<image>\nShould this bathroom be cleaned?\nAnswer the question using a single word or phrase."
            },
            {
                "from": "gpt",
                "value": "Yes"
            },
            {
                "from": "human",
                "value": "Is there a box in the bathroom?"
            },
            {
                "from": "gpt",
                "value": "Yes"
            },
            {
                "from": "human",
                "value": "Has this floor been mopped?"
            },
            {
                "from": "gpt",
                "value": "No"
            }
        ],
        "images": [
            "llava_image_tune/coco/train2017/000000494192.jpg"
        ],
        "textual_length": 1000
    },
    {
        "id": 546815,
        "conversations": [
            {
                "from": "human",
                "value": "<image>\nWho is the author of this book?\nAnswer the question using a single word or phrase."
            },
            {
                "from": "gpt",
                "value": "M.D. Henry Emmons"
            },
            {
                "from": "human",
                "value": "What is the title of this book?"
            },
            {
                "from": "gpt",
                "value": "The Chemistry of Joy: A Three-Step Program for Overcoming Depression Through Western Science and Eastern Wisdom"
            },
            {
                "from": "human",
                "value": "What type of book is this?"
            },
            {
                "from": "gpt",
                "value": "Religion & Spirituality"
            },
            {
                "from": "human",
                "value": "Is this book related to Religion & Spirituality?"
            },
            {
                "from": "gpt",
                "value": "Yes"
            },
            {
                "from": "human",
                "value": "Is this book related to Science & Math?"
            },
            {
                "from": "gpt",
                "value": "No"
            }
        ],
        "images": [
            "llava_image_tune/ocr_vqa/images/743265076.jpg"
        ],
        "textual_length": 1000
    },
    {
        "id": 429126,
        "conversations": [
            {
                "from": "human",
                "value": "<image>\nPlease provide the bounding box coordinate of the region this sentence describes: windows on top of train."
            },
            {
                "from": "gpt",
                "value": "[0.19, 0.41, 0.44, 0.5]"
            },
            {
                "from": "human",
                "value": "Please provide a short description for this region: [0.43, 0.41, 0.48, 0.58]."
            },
            {
                "from": "gpt",
                "value": "Front door of train."
            },
            {
                "from": "human",
                "value": "Please provide a short description for this region: [0.29, 0.44, 0.32, 0.48]."
            },
            {
                "from": "gpt",
                "value": "Small window on a train."
            },
            {
                "from": "human",
                "value": "Please provide a short description for this region: [0.51, 0.37, 0.66, 0.45]."
            },
            {
                "from": "gpt",
                "value": "Wipes on windshield."
            },
            {
                "from": "human",
                "value": "Please provide the bounding box coordinate of the region this sentence describes: a black telephone pole beyond the wall."
            },
            {
                "from": "gpt",
                "value": "[0.48, 0.22, 0.53, 0.35]"
            },
            {
                "from": "human",
                "value": "Please provide a short description for this region: [0.03, 0.31, 0.21, 0.44]."
            },
            {
                "from": "gpt",
                "value": "Apartment building with many windows."
            },
            {
                "from": "human",
                "value": "Please provide a short description for this region: [0.44, 0.42, 0.48, 0.58]."
            },
            {
                "from": "gpt",
                "value": "Door on first train car."
            },
            {
                "from": "human",
                "value": "Please provide a short description for this region: [0.39, 0.42, 0.44, 0.46]."
            },
            {
                "from": "gpt",
                "value": "Small window on a black train."
            },
            {
                "from": "human",
                "value": "Please provide a short description for this region: [0.37, 0.43, 0.4, 0.47]."
            },
            {
                "from": "gpt",
                "value": "Small window on a train."
            }
        ],
        "images": [
            "llava_image_tune/vg/VG_100K/2336655.jpg"
        ],
        "textual_length": 1000
    },
    {
        "id": 294732,
        "conversations": [
            {
                "from": "human",
                "value": "<image>\nWhat is the device on the middle shelf sitting to the right of the printer?\nA. scanner\nB. laptop\nC. hard drive\nD. router\nAnswer with the option's letter from the given choices directly."
            },
            {
                "from": "gpt",
                "value": "A"
            }
        ],
        "images": [
            "llava_image_tune/coco/train2017/000000294330.jpg"
        ],
        "textual_length": 1000
    },
    {
        "id": 460106,
        "conversations": [
            {
                "from": "human",
                "value": "<image>\nWhat color is the shirt?\nAnswer the question using a single word or phrase."
            },
            {
                "from": "gpt",
                "value": "White"
            },
            {
                "from": "human",
                "value": "Is there a plate or a chair in this picture?"
            },
            {
                "from": "gpt",
                "value": "Yes"
            },
            {
                "from": "human",
                "value": "Are there both a chair and a television in the image?"
            },
            {
                "from": "gpt",
                "value": "No"
            },
            {
                "from": "human",
                "value": "Is there a bed or a chair in this photo?"
            },
            {
                "from": "gpt",
                "value": "Yes"
            },
            {
                "from": "human",
                "value": "Are there both a desk and a chair in the photo?"
            },
            {
                "from": "gpt",
                "value": "No"
            }
        ],
        "images": [
            "llava_image_tune/gqa/images/3892.jpg"
        ],
        "textual_length": 1000
    },
    {
        "id": 512613,
        "conversations": [
            {
                "from": "human",
                "value": "<image>\nDoes the umbrella that is to the right of the other umbrellas look black?\nAnswer the question using a single word or phrase."
            },
            {
                "from": "gpt",
                "value": "Yes"
            },
            {
                "from": "human",
                "value": "Which place is it?"
            },
            {
                "from": "gpt",
                "value": "Stadium"
            },
            {
                "from": "human",
                "value": "Are there either any beach chairs or umbrellas?"
            },
            {
                "from": "gpt",
                "value": "Yes"
            },
            {
                "from": "human",
                "value": "Which side of the picture is the catcher on?"
            },
            {
                "from": "gpt",
                "value": "Left"
            },
            {
                "from": "human",
                "value": "What is the color of the umbrella that is to the left of the other umbrellas?"
            },
            {
                "from": "gpt",
                "value": "Blue"
            }
        ],
        "images": [
            "llava_image_tune/gqa/images/2351841.jpg"
        ],
        "textual_length": 1000
    },
    {
        "id": 21841,
        "conversations": [
            {
                "from": "human",
                "value": "<image>\nWhat is the person doing in the image?"
            },
            {
                "from": "gpt",
                "value": "The person in the image is surfing, riding a wave on a surfboard with the sky in the background."
            },
            {
                "from": "human",
                "value": "Is the wave the surfer is riding small or big?"
            },
            {
                "from": "gpt",
                "value": "The surfer is riding a big wave in the image."
            },
            {
                "from": "human",
                "value": "How can you describe the overall setting of the image?"
            },
            {
                "from": "gpt",
                "value": "The overall setting of the image is a sunny outdoor environment where water, waves, and sky are visible. The surfer is skillfully riding the wave, showcasing their abilities and athleticism within this pleasant and scenic backdrop."
            },
            {
                "from": "human",
                "value": "What skills are required for surfing, and what are the potential risks and challenges?"
            },
            {
                "from": "gpt",
                "value": "Surfing requires a unique combination of skills, including balance, strength, agility, endurance, and an understanding of water currents and wave patterns. Being proficient in these skills is essential for successfully navigating and riding waves on a surfboard. \n\n1. Balance: To maintain a stable position on a surfboard, surfers must have excellent balance and core strength. This is important for managing the ever-changing forces and motion of the water while keeping control over their surfboard.\n\n2. Strength and Agility: Surfers need upper body strength to paddle out into the waves and lower body strength to maneuver their surfboard and make quick turns. Agility is essential for adapting to the unpredictable nature of waves, avoiding obstacles, and safely exiting waves.\n\n3. Endurance: Surfing demands cardiovascular fitness and endurance to paddle out, catch waves, and maintain energy levels throughout the entire surf session.\n\n4. Understanding of Water Currents and Wave Patterns: Surfers must develop a keen understanding of water currents, wave patterns, and their surfboard's behavior in different conditions to anticipate upcoming movements and know when to catch and ride waves.\n\nPotential risks and challenges in surfing include:\n\n1. Injuries: Surfing can result in injuries caused by wipeouts, collisions with other surfers, or contact with the surfboard, reefs, or sand.\n\n2. Drowning: A surfer may get caught in a strong rip current or face difficulty swimming back to the surface after a wipeout, which can result in drowning.\n\n3. Environmental Hazards: Surfing in polluted water, encountering marine life such as sharks or jellyfish, and getting exposed to extreme weather conditions may pose additional risks.\n\n4. Physical and Mental Pressure: Surfing in big waves or crowded conditions can be physically and mentally challenging, leading to fatigue or stress.\n\nIn conclusion, surfing is a dynamic sport that requires an array of skills and understanding of the ocean's behavior. Although it can be exhilarating and rewarding, surfers must also navigate potential risks and challenges to ensure safety and success in the sport."
            }
        ],
        "images": [
            "llava_image_tune/coco/train2017/000000417016.jpg"
        ],
        "textual_length": 1000
    },
    {
        "id": 44905,
        "conversations": [
            {
                "from": "human",
                "value": "<image>\nWhat activity is the man engaged in the image?"
            },
            {
                "from": "gpt",
                "value": "The man in the image is engaged in cross-country skiing on a trail through the snow-covered woods."
            },
            {
                "from": "human",
                "value": "How many skiers are visible in the photo?"
            },
            {
                "from": "gpt",
                "value": "There is only one skier visible in the photo, who is a man."
            },
            {
                "from": "human",
                "value": "Is the trail in the woods or in an open area?"
            },
            {
                "from": "gpt",
                "value": "The trail is through the woods, as evidenced by the presence of a snow-covered forest in the image."
            },
            {
                "from": "human",
                "value": "What is the difference between cross-country skiing on a trail and cross-country skiing off-trail?"
            },
            {
                "from": "gpt",
                "value": "Cross-country skiing on a trail, also known as groomed trail skiing or track skiing, involves skiing on dedicated and maintained trails. These trails are usually prepared by machines or volunteers that pack down the snow and create parallel grooves or tracks, allowing for smoother and more efficient skiing. Skiers using groomed trails mostly practice the classic skiing technique, which involves gliding forward in the parallel tracks, although some trails may also support skate skiing.\n\nOn the other hand, cross-country skiing off-trail, also known as backcountry skiing or off-track skiing, is a more adventurous form of skiing that involves skiing on ungroomed and unmarked terrain. Skiers venture off the beaten track and navigate through a variety of natural landscapes, such as forests, open fields, hills, and frozen lakes. Off-trail skiing typically requires different equipment, skills, and techniques compared to groomed trail skiing, considering the uneven and often challenging terrain.\n\nIn summary, the main difference between skiing on a trail and skiing off-trail is the terrain on which the skiing occurs. Groomed trail skiing takes place on prepared paths with tracks and a relatively smooth surface, whereas off-trail skiing involves navigating through natural, ungroomed landscapes. Off-trail skiing tends to be more adventurous and challenging in terms of both terrain and technique."
            }
        ],
        "images": [
            "llava_image_tune/coco/train2017/000000010024.jpg"
        ],
        "textual_length": 1000
    },
    {
        "id": 179801,
        "conversations": [
            {
                "from": "human",
                "value": "<image>\nWhat are the animals with the curly tails?\nAnswer the question using a single word or phrase."
            },
            {
                "from": "gpt",
                "value": "Dogs"
            },
            {
                "from": "human",
                "value": "What color is the person's head covering?"
            },
            {
                "from": "gpt",
                "value": "Blue"
            },
            {
                "from": "human",
                "value": "How many animals are attentive?"
            },
            {
                "from": "gpt",
                "value": "2"
            },
            {
                "from": "human",
                "value": "What is in the background?"
            },
            {
                "from": "gpt",
                "value": "Trees"
            },
            {
                "from": "human",
                "value": "What is this environment?"
            },
            {
                "from": "gpt",
                "value": "Desert"
            },
            {
                "from": "human",
                "value": "What color is the goat?"
            },
            {
                "from": "gpt",
                "value": "Gray"
            },
            {
                "from": "human",
                "value": "Are shadows cast?"
            },
            {
                "from": "gpt",
                "value": "No"
            },
            {
                "from": "human",
                "value": "How many types of animals are in the picture?"
            },
            {
                "from": "gpt",
                "value": "3"
            },
            {
                "from": "human",
                "value": "How many animals are running?"
            },
            {
                "from": "gpt",
                "value": "Many"
            },
            {
                "from": "human",
                "value": "Are these animals walking on a hill?"
            },
            {
                "from": "gpt",
                "value": "No"
            },
            {
                "from": "human",
                "value": "Where is the dog?"
            },
            {
                "from": "gpt",
                "value": "Rear"
            }
        ],
        "images": [
            "llava_image_tune/coco/train2017/000000295537.jpg"
        ],
        "textual_length": 1000
    },
    {
        "id": 582360,
        "conversations": [
            {
                "from": "human",
                "value": "<image>\nWho wrote this book?\nAnswer the question using a single word or phrase."
            },
            {
                "from": "gpt",
                "value": "David Howarth"
            },
            {
                "from": "human",
                "value": "What is the title of this book?"
            },
            {
                "from": "gpt",
                "value": "We Die Alone: A WWII Epic Of Escape And Endurance"
            },
            {
                "from": "human",
                "value": "What is the genre of this book?"
            },
            {
                "from": "gpt",
                "value": "History"
            },
            {
                "from": "human",
                "value": "Is this a historical book?"
            },
            {
                "from": "gpt",
                "value": "Yes"
            },
            {
                "from": "human",
                "value": "Is this a judicial book?"
            },
            {
                "from": "gpt",
                "value": "No"
            }
        ],
        "images": [
            "llava_image_tune/ocr_vqa/images/1599210630.jpg"
        ],
        "textual_length": 1000
    },
    {
        "id": 481723,
        "conversations": [
            {
                "from": "human",
                "value": "<image>\nWhat do the clouds and the flags have in common?\nAnswer the question using a single word or phrase."
            },
            {
                "from": "gpt",
                "value": "Color"
            },
            {
                "from": "human",
                "value": "Are there any kites?"
            },
            {
                "from": "gpt",
                "value": "Yes"
            },
            {
                "from": "human",
                "value": "On which side of the picture are the flags?"
            },
            {
                "from": "gpt",
                "value": "Right"
            }
        ],
        "images": [
            "llava_image_tune/gqa/images/2329447.jpg"
        ],
        "textual_length": 1000
    },
    {
        "id": 97621,
        "conversations": [
            {
                "from": "human",
                "value": "<image>\nWhat role did the clock tower likely serve in the past?"
            },
            {
                "from": "gpt",
                "value": "In the past, the clock tower likely served as a central timekeeping device for the local community. Before the widespread use of personal watches and smartphones, people relied on public clocks like the one in the image to know the time. The tower, which is made of brick, prominently displays the clock at a higher altitude to ensure visibility from a distance. The position on top of a brick building further emphasizes its significance in the area, providing a visual and practical landmark for both residents and visitors. The clock tower thus played a vital role in daily life, helping people organize their activities, synchronize their work schedules, and coordinate meetings and events."
            }
        ],
        "images": [
            "llava_image_tune/coco/train2017/000000076910.jpg"
        ],
        "textual_length": 1000
    },
    {
        "id": 498073,
        "conversations": [
            {
                "from": "human",
                "value": "<image>\nWhat is the picture showing?\nAnswer the question using a single word or phrase."
            },
            {
                "from": "gpt",
                "value": "Patio"
            },
            {
                "from": "human",
                "value": "Which place is it?"
            },
            {
                "from": "gpt",
                "value": "Patio"
            },
            {
                "from": "human",
                "value": "Which color is the shirt?"
            },
            {
                "from": "gpt",
                "value": "Black"
            },
            {
                "from": "human",
                "value": "Is the kid wearing a coat?"
            },
            {
                "from": "gpt",
                "value": "No"
            },
            {
                "from": "human",
                "value": "Who is wearing a shirt?"
            },
            {
                "from": "gpt",
                "value": "Child"
            },
            {
                "from": "human",
                "value": "Who is wearing the shirt?"
            },
            {
                "from": "gpt",
                "value": "Child"
            },
            {
                "from": "human",
                "value": "Are there nightstands in this picture?"
            },
            {
                "from": "gpt",
                "value": "No"
            },
            {
                "from": "human",
                "value": "What is the chair on?"
            },
            {
                "from": "gpt",
                "value": "Deck"
            },
            {
                "from": "human",
                "value": "Is the child to the right or to the left of the chair on the deck?"
            },
            {
                "from": "gpt",
                "value": "Left"
            },
            {
                "from": "human",
                "value": "On which side is the chair?"
            },
            {
                "from": "gpt",
                "value": "Right"
            },
            {
                "from": "human",
                "value": "Who is wearing the dress?"
            },
            {
                "from": "gpt",
                "value": "Child"
            },
            {
                "from": "human",
                "value": "Who is wearing a dress?"
            },
            {
                "from": "gpt",
                "value": "Child"
            },
            {
                "from": "human",
                "value": "What is the kid on?"
            },
            {
                "from": "gpt",
                "value": "Deck"
            },
            {
                "from": "human",
                "value": "What is the child on?"
            },
            {
                "from": "gpt",
                "value": "Deck"
            }
        ],
        "images": [
            "llava_image_tune/gqa/images/2345743.jpg"
        ],
        "textual_length": 1000
    },
    {
        "id": 482147,
        "conversations": [
            {
                "from": "human",
                "value": "<image>\nWhich side of the image is the mirror on?\nAnswer the question using a single word or phrase."
            },
            {
                "from": "gpt",
                "value": "Left"
            },
            {
                "from": "human",
                "value": "Are there both a cabinet and a mirror?"
            },
            {
                "from": "gpt",
                "value": "Yes"
            },
            {
                "from": "human",
                "value": "On which side of the picture is the dispenser?"
            },
            {
                "from": "gpt",
                "value": "Left"
            },
            {
                "from": "human",
                "value": "Is the mirror both large and clean?"
            },
            {
                "from": "gpt",
                "value": "Yes"
            },
            {
                "from": "human",
                "value": "Are there plates near the glass that is drinking?"
            },
            {
                "from": "gpt",
                "value": "No"
            },
            {
                "from": "human",
                "value": "What color is the mat in the bottom of the image?"
            },
            {
                "from": "gpt",
                "value": "White"
            },
            {
                "from": "human",
                "value": "What is the item of furniture that is made of wood called?"
            },
            {
                "from": "gpt",
                "value": "Cabinet"
            },
            {
                "from": "human",
                "value": "What item of furniture is wooden?"
            },
            {
                "from": "gpt",
                "value": "Cabinet"
            },
            {
                "from": "human",
                "value": "Which type of furniture is this?"
            },
            {
                "from": "gpt",
                "value": "Cabinet"
            },
            {
                "from": "human",
                "value": "What item of furniture is made of wood?"
            },
            {
                "from": "gpt",
                "value": "Cabinet"
            },
            {
                "from": "human",
                "value": "Do both the faucet near the glass and the dispenser to the left of the towel appear to be silver?"
            },
            {
                "from": "gpt",
                "value": "Yes"
            },
            {
                "from": "human",
                "value": "Does that floor look white and light?"
            },
            {
                "from": "gpt",
                "value": "Yes"
            },
            {
                "from": "human",
                "value": "Is the sink black or silver?"
            },
            {
                "from": "gpt",
                "value": "Silver"
            },
            {
                "from": "human",
                "value": "Which kind of furniture is it?"
            },
            {
                "from": "gpt",
                "value": "Cabinet"
            }
        ],
        "images": [
            "llava_image_tune/gqa/images/2349469.jpg"
        ],
        "textual_length": 1000
    },
    {
        "id": 412169,
        "conversations": [
            {
                "from": "human",
                "value": "<image>\nPlease provide a short description for this region: [0.08, 0.51, 0.29, 0.71]."
            },
            {
                "from": "gpt",
                "value": "The front wheel of a motorcycle."
            },
            {
                "from": "human",
                "value": "Please provide the bounding box coordinate of the region this sentence describes: the headlight of a motorcycle."
            },
            {
                "from": "gpt",
                "value": "[0.32, 0.41, 0.37, 0.44]"
            },
            {
                "from": "human",
                "value": "Please provide the bounding box coordinate of the region this sentence describes: a dark helmet on his head."
            },
            {
                "from": "gpt",
                "value": "[0.57, 0.33, 0.67, 0.38]"
            },
            {
                "from": "human",
                "value": "Please provide the bounding box coordinate of the region this sentence describes: rear motorcycle tire and fender."
            },
            {
                "from": "gpt",
                "value": "[0.67, 0.52, 0.79, 0.68]"
            },
            {
                "from": "human",
                "value": "Please provide the bounding box coordinate of the region this sentence describes: the wheel is black."
            },
            {
                "from": "gpt",
                "value": "[0.68, 0.55, 0.79, 0.68]"
            },
            {
                "from": "human",
                "value": "Please provide the bounding box coordinate of the region this sentence describes: white lines on the road."
            },
            {
                "from": "gpt",
                "value": "[0.01, 0.53, 0.48, 0.83]"
            },
            {
                "from": "human",
                "value": "Please provide the bounding box coordinate of the region this sentence describes: black helmet on man's head."
            },
            {
                "from": "gpt",
                "value": "[0.55, 0.32, 0.66, 0.4]"
            },
            {
                "from": "human",
                "value": "Please provide the bounding box coordinate of the region this sentence describes: the handle bars of a motorcycle."
            },
            {
                "from": "gpt",
                "value": "[0.4, 0.4, 0.54, 0.46]"
            },
            {
                "from": "human",
                "value": "Please provide a short description for this region: [0.46, 0.51, 0.65, 0.65]."
            },
            {
                "from": "gpt",
                "value": "Man wearing light blue jeans."
            },
            {
                "from": "human",
                "value": "Please provide a short description for this region: [0.49, 0.39, 0.53, 0.42]."
            },
            {
                "from": "gpt",
                "value": "The mirror of a motorcycle."
            }
        ],
        "images": [
            "llava_image_tune/vg/VG_100K/2358726.jpg"
        ],
        "textual_length": 1000
    },
    {
        "id": 205458,
        "conversations": [
            {
                "from": "human",
                "value": "<image>\nHow many trains are here?\nAnswer the question using a single word or phrase."
            },
            {
                "from": "gpt",
                "value": "3"
            },
            {
                "from": "human",
                "value": "How many tracks are seen?"
            },
            {
                "from": "gpt",
                "value": "3"
            },
            {
                "from": "human",
                "value": "How many trains are red?"
            },
            {
                "from": "gpt",
                "value": "1"
            }
        ],
        "images": [
            "llava_image_tune/coco/train2017/000000466621.jpg"
        ],
        "textual_length": 1000
    },
    {
        "id": 385655,
        "conversations": [
            {
                "from": "human",
                "value": "<image>\nPlease provide a short description for this region: [0.14, 0.46, 0.19, 0.51]."
            },
            {
                "from": "gpt",
                "value": "A small red cone."
            },
            {
                "from": "human",
                "value": "Please provide the bounding box coordinate of the region this sentence describes: Adidas shoes a guy has on."
            },
            {
                "from": "gpt",
                "value": "[0.4, 0.76, 0.71, 0.81]"
            },
            {
                "from": "human",
                "value": "Please provide the bounding box coordinate of the region this sentence describes: sky blue sweater with hootie."
            },
            {
                "from": "gpt",
                "value": "[0.45, 0.26, 0.61, 0.58]"
            },
            {
                "from": "human",
                "value": "Please provide the bounding box coordinate of the region this sentence describes: A red tennis racket."
            },
            {
                "from": "gpt",
                "value": "[0.31, 0.53, 0.56, 0.72]"
            },
            {
                "from": "human",
                "value": "Please provide the bounding box coordinate of the region this sentence describes: A small red cone."
            },
            {
                "from": "gpt",
                "value": "[0.13, 0.54, 0.19, 0.59]"
            },
            {
                "from": "human",
                "value": "Please provide the bounding box coordinate of the region this sentence describes: A small red cone."
            },
            {
                "from": "gpt",
                "value": "[0.79, 0.46, 0.83, 0.51]"
            },
            {
                "from": "human",
                "value": "Please provide a short description for this region: [0.4, 0.75, 0.72, 0.82]."
            },
            {
                "from": "gpt",
                "value": "The shoes are black and white."
            },
            {
                "from": "human",
                "value": "Please provide a short description for this region: [0.38, 0.48, 0.71, 0.8]."
            },
            {
                "from": "gpt",
                "value": "The pants are blue."
            },
            {
                "from": "human",
                "value": "Please provide the bounding box coordinate of the region this sentence describes: A small red cone."
            },
            {
                "from": "gpt",
                "value": "[0.83, 0.54, 0.87, 0.59]"
            },
            {
                "from": "human",
                "value": "Please provide the bounding box coordinate of the region this sentence describes: mans right blue and white tennis shoe."
            },
            {
                "from": "gpt",
                "value": "[0.6, 0.74, 0.72, 0.81]"
            }
        ],
        "images": [
            "llava_image_tune/vg/VG_100K_2/2394232.jpg"
        ],
        "textual_length": 1000
    },
    {
        "id": 557236,
        "conversations": [
            {
                "from": "human",
                "value": "<image>\nWho wrote this book?\nAnswer the question using a single word or phrase."
            },
            {
                "from": "gpt",
                "value": "Patrick G. Riley"
            },
            {
                "from": "human",
                "value": "What is the title of this book?"
            },
            {
                "from": "gpt",
                "value": "The One-Page Proposal:  How to Get Your Business Pitch onto One Persuasive Page"
            },
            {
                "from": "human",
                "value": "What is the genre of this book?"
            },
            {
                "from": "gpt",
                "value": "Business & Money"
            },
            {
                "from": "human",
                "value": "Is this a financial book?"
            },
            {
                "from": "gpt",
                "value": "Yes"
            }
        ],
        "images": [
            "llava_image_tune/ocr_vqa/images/60988606.jpg"
        ],
        "textual_length": 1000
    },
    {
        "id": 68290,
        "conversations": [
            {
                "from": "human",
                "value": "<image>\nCan you elaborate on the elements of the picture provided?"
            },
            {
                "from": "gpt",
                "value": "The image depicts a diverse group of men and women gathered together, possibly in a classroom or courtroom setting. They are all sitting next to each other and smiling, likely posing for a group photo. In total, there are 12 people visible in the scene, with some individuals located closer to the foreground and others further back.\n\nThere is a laptop placed in the foreground, suggesting that the people may be using it for their work or studies. A water bottle is also visible on a surface, possibly belonging to someone in the group. Overall, this scene conveys a sense of collaboration and camaraderie among the people present."
            }
        ],
        "images": [
            "llava_image_tune/coco/train2017/000000190882.jpg"
        ],
        "textual_length": 1000
    },
    {
        "id": 593616,
        "conversations": [
            {
                "from": "human",
                "value": "<image>\nWho is the author of this book?\nAnswer the question using a single word or phrase."
            },
            {
                "from": "gpt",
                "value": "Theodore Dwight Weld"
            },
            {
                "from": "human",
                "value": "What is the title of this book?"
            },
            {
                "from": "gpt",
                "value": "American Slavery As It Is: Testimony of a Thousand Witnesses"
            },
            {
                "from": "human",
                "value": "What is the genre of this book?"
            },
            {
                "from": "gpt",
                "value": "History"
            },
            {
                "from": "human",
                "value": "Is this a historical book?"
            },
            {
                "from": "gpt",
                "value": "Yes"
            },
            {
                "from": "human",
                "value": "Is this a games related book?"
            },
            {
                "from": "gpt",
                "value": "No"
            }
        ],
        "images": [
            "llava_image_tune/ocr_vqa/images/807869570.jpg"
        ],
        "textual_length": 1000
    },
    {
        "id": 386483,
        "conversations": [
            {
                "from": "human",
                "value": "<image>\nPlease provide a short description for this region: [0.27, 0.34, 0.3, 0.43]."
            },
            {
                "from": "gpt",
                "value": "Someone wearing a red shirt."
            },
            {
                "from": "human",
                "value": "Please provide a short description for this region: [0.81, 0.28, 1.0, 0.32]."
            },
            {
                "from": "gpt",
                "value": "Sign on the front of the building."
            },
            {
                "from": "human",
                "value": "Please provide the bounding box coordinate of the region this sentence describes: a flooded street."
            },
            {
                "from": "gpt",
                "value": "[0.21, 0.48, 0.61, 0.8]"
            },
            {
                "from": "human",
                "value": "Please provide the bounding box coordinate of the region this sentence describes: long yellow sign."
            },
            {
                "from": "gpt",
                "value": "[0.21, 0.17, 0.24, 0.28]"
            },
            {
                "from": "human",
                "value": "Please provide a short description for this region: [0.53, 0.36, 0.56, 0.43]."
            },
            {
                "from": "gpt",
                "value": "A person wearing a green and white shirt."
            },
            {
                "from": "human",
                "value": "Please provide a short description for this region: [0.64, 0.25, 0.77, 0.39]."
            },
            {
                "from": "gpt",
                "value": "Woman has dark hair."
            },
            {
                "from": "human",
                "value": "Please provide the bounding box coordinate of the region this sentence describes: Car parked beside sidewalk."
            },
            {
                "from": "gpt",
                "value": "[0.84, 0.36, 1.0, 0.48]"
            },
            {
                "from": "human",
                "value": "Please provide a short description for this region: [0.17, 0.57, 0.97, 0.74]."
            },
            {
                "from": "gpt",
                "value": "Rushing water in the gutter of the street."
            },
            {
                "from": "human",
                "value": "Please provide the bounding box coordinate of the region this sentence describes: Woman crossing the street."
            },
            {
                "from": "gpt",
                "value": "[0.66, 0.28, 0.95, 0.81]"
            },
            {
                "from": "human",
                "value": "Please provide the bounding box coordinate of the region this sentence describes: an arrow on a pole."
            },
            {
                "from": "gpt",
                "value": "[0.08, 0.21, 0.17, 0.32]"
            }
        ],
        "images": [
            "llava_image_tune/vg/VG_100K_2/2393128.jpg"
        ],
        "textual_length": 1000
    },
    {
        "id": 315808,
        "conversations": [
            {
                "from": "human",
                "value": "<image>\nPlease provide the bounding box coordinate of the region this sentence describes: bride."
            },
            {
                "from": "gpt",
                "value": "[0.4, 0.38, 0.54, 0.8]"
            },
            {
                "from": "human",
                "value": "Please provide the bounding box coordinate of the region this sentence describes: woman in blue with brunett hair."
            },
            {
                "from": "gpt",
                "value": "[0.69, 0.42, 0.99, 0.79]"
            },
            {
                "from": "human",
                "value": "Please provide the bounding box coordinate of the region this sentence describes: bride."
            },
            {
                "from": "gpt",
                "value": "[0.4, 0.38, 0.54, 0.8]"
            },
            {
                "from": "human",
                "value": "Please provide a short description for this region: [0.0, 0.37, 0.39, 0.8]."
            },
            {
                "from": "gpt",
                "value": "Far left man."
            },
            {
                "from": "human",
                "value": "Please provide the bounding box coordinate of the region this sentence describes: bride."
            },
            {
                "from": "gpt",
                "value": "[0.4, 0.38, 0.54, 0.8]"
            },
            {
                "from": "human",
                "value": "Please provide a short description for this region: [0.11, 0.29, 0.26, 0.75]."
            },
            {
                "from": "gpt",
                "value": "End of row standing arms ceossed."
            },
            {
                "from": "human",
                "value": "Please provide a short description for this region: [0.11, 0.29, 0.26, 0.75]."
            },
            {
                "from": "gpt",
                "value": "First guy standing from left."
            }
        ],
        "images": [
            "llava_image_tune/coco/train2017/000000430702.jpg"
        ],
        "textual_length": 1000
    },
    {
        "id": 615221,
        "conversations": [
            {
                "from": "human",
                "value": "<image>\nProvide a one-sentence caption for the provided image.\nReference OCR token: 2XIP, 2XIP, IPA, PA, 2XIP, RR, 2XIP, PA, SOUTHC, SOUTH, OUTH, THER, SOUTHE, Merry, Jerkmas!"
            },
            {
                "from": "gpt",
                "value": "Several bottles of 2XIPA are lined up near a card that says Merry Jerkmas!."
            }
        ],
        "images": [
            "llava_image_tune/textvqa/train_images/28d5e1e6ac905386.jpg"
        ],
        "textual_length": 1000
    },
    {
        "id": 204880,
        "conversations": [
            {
                "from": "human",
                "value": "<image>\nWhat are they on?\nAnswer the question using a single word or phrase."
            },
            {
                "from": "gpt",
                "value": "Surfboards"
            },
            {
                "from": "human",
                "value": "Is this a warm climate setting?"
            },
            {
                "from": "gpt",
                "value": "Yes"
            },
            {
                "from": "human",
                "value": "Are the girls wearing the same color swimsuit?"
            },
            {
                "from": "gpt",
                "value": "Yes"
            },
            {
                "from": "human",
                "value": "How many people are shown?"
            },
            {
                "from": "gpt",
                "value": "2"
            }
        ],
        "images": [
            "llava_image_tune/coco/train2017/000000296067.jpg"
        ],
        "textual_length": 1000
    },
    {
        "id": 525106,
        "conversations": [
            {
                "from": "human",
                "value": "<image>\nWho wrote this book?\nAnswer the question using a single word or phrase."
            },
            {
                "from": "gpt",
                "value": "Linda Schele"
            },
            {
                "from": "human",
                "value": "What is the title of this book?"
            },
            {
                "from": "gpt",
                "value": "The Code of Kings: The Language of Seven Sacred Maya Temples and Tombs"
            },
            {
                "from": "human",
                "value": "What type of book is this?"
            },
            {
                "from": "gpt",
                "value": "History"
            },
            {
                "from": "human",
                "value": "Is this book related to History?"
            },
            {
                "from": "gpt",
                "value": "Yes"
            },
            {
                "from": "human",
                "value": "Is this book related to Computers & Technology?"
            },
            {
                "from": "gpt",
                "value": "No"
            }
        ],
        "images": [
            "llava_image_tune/ocr_vqa/images/684852098.jpg"
        ],
        "textual_length": 1000
    },
    {
        "id": 376746,
        "conversations": [
            {
                "from": "human",
                "value": "<image>\nPlease provide a short description for this region: [0.0, 0.57, 0.12, 0.65]."
            },
            {
                "from": "gpt",
                "value": "Mp3 player in stand/speaker."
            },
            {
                "from": "human",
                "value": "Please provide the bounding box coordinate of the region this sentence describes: steel colored knife set."
            },
            {
                "from": "gpt",
                "value": "[0.21, 0.4, 0.33, 0.52]"
            },
            {
                "from": "human",
                "value": "Please provide a short description for this region: [0.61, 0.28, 0.82, 0.68]."
            },
            {
                "from": "gpt",
                "value": "Stainless steel refrigerator with colored magnets on it."
            },
            {
                "from": "human",
                "value": "Please provide a short description for this region: [0.87, 0.19, 1.0, 0.44]."
            },
            {
                "from": "gpt",
                "value": "Large open window letting in light."
            },
            {
                "from": "human",
                "value": "Please provide the bounding box coordinate of the region this sentence describes: stainless steel range and cover."
            },
            {
                "from": "gpt",
                "value": "[0.25, 0.24, 0.45, 0.64]"
            },
            {
                "from": "human",
                "value": "Please provide the bounding box coordinate of the region this sentence describes: Ipod player on charger."
            },
            {
                "from": "gpt",
                "value": "[0.01, 0.55, 0.11, 0.65]"
            },
            {
                "from": "human",
                "value": "Please provide a short description for this region: [0.68, 0.42, 1.0, 0.77]."
            },
            {
                "from": "gpt",
                "value": "Sterile white kitchen counter."
            },
            {
                "from": "human",
                "value": "Please provide a short description for this region: [0.78, 0.42, 0.82, 0.49]."
            },
            {
                "from": "gpt",
                "value": "Dish washing detergent next to sink."
            },
            {
                "from": "human",
                "value": "Please provide the bounding box coordinate of the region this sentence describes: stainless steel oven and range."
            },
            {
                "from": "gpt",
                "value": "[0.27, 0.43, 0.43, 0.62]"
            },
            {
                "from": "human",
                "value": "Please provide a short description for this region: [0.4, 0.17, 0.65, 0.24]."
            },
            {
                "from": "gpt",
                "value": "Ceiling lights are recessed."
            }
        ],
        "images": [
            "llava_image_tune/vg/VG_100K_2/2406938.jpg"
        ],
        "textual_length": 1000
    },
    {
        "id": 176415,
        "conversations": [
            {
                "from": "human",
                "value": "<image>\nDoes the animal to the furthest right have a head?\nAnswer the question using a single word or phrase."
            },
            {
                "from": "gpt",
                "value": "Yes"
            },
            {
                "from": "human",
                "value": "What type of animals are these?"
            },
            {
                "from": "gpt",
                "value": "Sheep"
            },
            {
                "from": "human",
                "value": "Were these animals just shorn?"
            },
            {
                "from": "gpt",
                "value": "No"
            }
        ],
        "images": [
            "llava_image_tune/coco/train2017/000000376085.jpg"
        ],
        "textual_length": 1000
    },
    {
        "id": 253063,
        "conversations": [
            {
                "from": "human",
                "value": "<image>\nWhy is the machinery white?\nA. styrofoam\nB. painted white\nC. toilet paper\nD. snow covered\nAnswer with the option's letter from the given choices directly."
            },
            {
                "from": "gpt",
                "value": "D"
            }
        ],
        "images": [
            "llava_image_tune/coco/train2017/000000487456.jpg"
        ],
        "textual_length": 1000
    },
    {
        "id": 511568,
        "conversations": [
            {
                "from": "human",
                "value": "<image>\nAre there glasses to the right of the man that is wearing a necktie?\nAnswer the question using a single word or phrase."
            },
            {
                "from": "gpt",
                "value": "No"
            },
            {
                "from": "human",
                "value": "Is the man's hair short or long?"
            },
            {
                "from": "gpt",
                "value": "Short"
            },
            {
                "from": "human",
                "value": "On which side of the image is the dark drink?"
            },
            {
                "from": "gpt",
                "value": "Right"
            },
            {
                "from": "human",
                "value": "Is the man to the right of the glasses wearing a tie?"
            },
            {
                "from": "gpt",
                "value": "Yes"
            },
            {
                "from": "human",
                "value": "Is the shirt black or red?"
            },
            {
                "from": "gpt",
                "value": "Red"
            },
            {
                "from": "human",
                "value": "How does the drink to the right of the man seem to be, red or dark?"
            },
            {
                "from": "gpt",
                "value": "Dark"
            }
        ],
        "images": [
            "llava_image_tune/gqa/images/2360391.jpg"
        ],
        "textual_length": 1000
    },
    {
        "id": 26166,
        "conversations": [
            {
                "from": "human",
                "value": "<image>\nWhat activity is the person in the image engaged in?"
            },
            {
                "from": "gpt",
                "value": "The person in the image is engaged in the activity of flying a kite."
            },
            {
                "from": "human",
                "value": "Is there only one person in the image or are there other people as well?"
            },
            {
                "from": "gpt",
                "value": "In addition to the person flying the kite, there is another person watching from the side."
            },
            {
                "from": "human",
                "value": "What is the setting of the image?"
            },
            {
                "from": "gpt",
                "value": "The image takes place in an open grassy field."
            },
            {
                "from": "human",
                "value": "Do the people in the image appear to be young or older?"
            },
            {
                "from": "gpt",
                "value": "Based on the available descriptions, at least one of the individuals in the image, the man flying the kite, is described as being older."
            },
            {
                "from": "human",
                "value": "What can you tell me about the kite in the image?"
            },
            {
                "from": "gpt",
                "value": "The kite in the image appears to be small and is being controlled by the person holding two lines attached to it. This configuration allows for the manipulation of the kite's flight, direction, and height. Kite flying is a leisurely outdoor activity enjoyed by people of all ages and can be a fun and relaxing way to spend time outside. Flying a kite requires open space with little to no obstruction, like trees or buildings, and a steady wind to help keep the kite in the air. The field setting in the image would be an ideal location for kite flying."
            }
        ],
        "images": [
            "llava_image_tune/coco/train2017/000000578856.jpg"
        ],
        "textual_length": 1000
    }
]